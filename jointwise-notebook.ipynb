{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7703244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports for ensemble learning pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch deep learning framework\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "import timm  # For Xception and other models\n",
    "\n",
    "# Data augmentation\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Machine learning utilities\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve, roc_curve, accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Genetic algorithm for hyperparameter optimization\n",
    "import deap\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# --- Step 1: FastMRI to DICOM ---\n",
    "import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pydicom\n",
    "from pydicom.dataset import Dataset, FileMetaDataset\n",
    "from pydicom.uid import generate_uid\n",
    "import xmltodict\n",
    "\n",
    "import pydicom\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae3c1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastmri_to_dicom(filename: Path,\n",
    "    reconstruction_name: str,\n",
    "    outfolder: Path,\n",
    "    flip_up_down: bool = False,\n",
    "    flip_left_right: bool = False) -> None:\n",
    "    fileparts = os.path.splitext(filename.name)\n",
    "    patientName = fileparts[0]\n",
    "    f = h5py.File(filename,'r')\n",
    "    if not outfolder:\n",
    "        outfolder = Path(patientName)\n",
    "        outfolder.mkdir(parents=True, exist_ok=True)\n",
    "    if 'ismrmrd_header' not in f.keys():\n",
    "        raise Exception('ISMRMRD header not found in file')\n",
    "    if reconstruction_name not in f.keys():\n",
    "        raise Exception('Reconstruction name not found in file')\n",
    "    head = xmltodict.parse(f['ismrmrd_header'][()])\n",
    "    reconSpace = head['ismrmrdHeader']['encoding']['reconSpace']\n",
    "    measurementInformation = head['ismrmrdHeader']['measurementInformation']\n",
    "    acquisitionSystemInformation = head['ismrmrdHeader']['acquisitionSystemInformation']\n",
    "    H1resonanceFrequency_Hz = head['ismrmrdHeader']['experimentalConditions']['H1resonanceFrequency_Hz']\n",
    "    sequenceParameters = head['ismrmrdHeader']['sequenceParameters']\n",
    "    pixelSizeX = float(reconSpace['fieldOfView_mm']['x'])/float(reconSpace['matrixSize']['x'])\n",
    "    pixelSizeY = float(reconSpace['fieldOfView_mm']['y'])/float(reconSpace['matrixSize']['y'])\n",
    "    img_data = f[reconstruction_name][:]\n",
    "    slices = img_data.shape[0]\n",
    "    if flip_left_right:\n",
    "        img_data = img_data[:, :, ::-1]\n",
    "    if flip_up_down:\n",
    "        img_data = img_data[:, ::-1, :]\n",
    "    image_max = 1024\n",
    "    scale = image_max / np.percentile(img_data, 99.9)\n",
    "    pixels_scaled = np.clip((scale * img_data), 0, image_max).astype('int16')\n",
    "    windowWidth = 2 * (np.percentile(pixels_scaled, 99.9) - np.percentile(pixels_scaled, 0.1))\n",
    "    windowCenter = windowWidth/2\n",
    "    studyInstanceUid = generate_uid('999.')\n",
    "    seriesInstanceUid = generate_uid('9999.')\n",
    "    for s in range(0, slices):\n",
    "        slice_filename = \"%s_%03d.dcm\"%(patientName, s)\n",
    "        slice_full_path = outfolder/slice_filename\n",
    "        slice_pixels = pixels_scaled[s,:,:]\n",
    "        file_meta = FileMetaDataset()\n",
    "        file_meta.MediaStorageSOPClassUID = '1.2.840.10008.5.1.4.1.1.4'\n",
    "        file_meta.MediaStorageSOPInstanceUID = \"1.2.3\"\n",
    "        file_meta.ImplementationClassUID = \"1.2.3.4\"\n",
    "        file_meta.TransferSyntaxUID = '1.2.840.10008.1.2.1'\n",
    "        ds = Dataset()\n",
    "        dt = datetime.datetime.now()\n",
    "        ds.ContentDate = dt.strftime('%Y%m%d')\n",
    "        timeStr = dt.strftime('%H%M%S.%f')\n",
    "        ds.SOPClassUID = '1.2.840.10008.5.1.4.1.1.4'\n",
    "        ds.SOPInstanceUID = generate_uid('9999.')\n",
    "        ds.ContentTime = timeStr\n",
    "        ds.Modality = 'MR'\n",
    "        ds.ModalitiesInStudy = ['', 'PR', 'MR', '']\n",
    "        ds.StudyDescription = measurementInformation['protocolName']\n",
    "        ds.PatientName = patientName\n",
    "        ds.PatientID = patientName\n",
    "        ds.PatientBirthDate = '19700101'\n",
    "        ds.PatientSex = 'M'\n",
    "        ds.PatientAge = '030Y'\n",
    "        ds.PatientIdentityRemoved = 'YES'\n",
    "        ds.MRAcquisitionType = '2D'\n",
    "        ds.SequenceName = sequenceParameters['sequence_type']\n",
    "        ds.SliceThickness = reconSpace['fieldOfView_mm']['z']\n",
    "        ds.RepetitionTime = sequenceParameters['TR']\n",
    "        ds.EchoTime = sequenceParameters['TE']\n",
    "        ds.ImagingFrequency = H1resonanceFrequency_Hz\n",
    "        ds.ImagedNucleus = '1H'\n",
    "        ds.EchoNumbers = \"1\"\n",
    "        ds.MagneticFieldStrength = acquisitionSystemInformation['systemFieldStrength_T']\n",
    "        ds.SpacingBetweenSlices = reconSpace['fieldOfView_mm']['z']\n",
    "        ds.FlipAngle = str(sequenceParameters['flipAngle_deg'])\n",
    "        ds.PatientPosition = measurementInformation['patientPosition']\n",
    "        ds.StudyInstanceUID = studyInstanceUid\n",
    "        ds.SeriesInstanceUID = seriesInstanceUid\n",
    "        ds.StudyID = measurementInformation['measurementID']\n",
    "        ds.InstanceNumber = str(s+1)\n",
    "        ds.ImagesInAcquisition = str(slices)\n",
    "        ds.SamplesPerPixel = 1\n",
    "        ds.PhotometricInterpretation = 'MONOCHROME2'\n",
    "        ds.NumberOfFrames = \"1\"\n",
    "        ds.Rows = slice_pixels.shape[0]\n",
    "        ds.Columns = slice_pixels.shape[1]\n",
    "        ds.PixelSpacing = [pixelSizeX, pixelSizeY]\n",
    "        ds.PixelAspectRatio = [1, 1]\n",
    "        ds.BitsAllocated = 16\n",
    "        ds.BitsStored = 12\n",
    "        ds.HighBit = 11\n",
    "        ds.PixelRepresentation = 1 \n",
    "        ds.SmallestImagePixelValue = 0\n",
    "        ds.LargestImagePixelValue = 1024\n",
    "        ds.BurnedInAnnotation = 'NO'\n",
    "        ds.WindowCenter = str(windowCenter)\n",
    "        ds.WindowWidth = str(windowWidth)\n",
    "        ds.LossyImageCompression = '00'\n",
    "        ds.StudyStatusID = 'COMPLETED'\n",
    "        ds.ResultsID = ''\n",
    "        # NOTE: The following method may need to be replaced with ds.PixelData assignment depending on pydicom version\n",
    "        ds.set_pixel_data(slice_pixels, 'MONOCHROME2', 12)\n",
    "        ds.file_meta = file_meta\n",
    "        ds.is_implicit_VR = False\n",
    "        ds.is_little_endian = True\n",
    "        ds.save_as(slice_full_path, write_like_original=False)\n",
    "# Example usage\n",
    "# fastmri_to_dicom(Path(\"/mnt/f/datasets/demo_data/file1000002.h5\"), \"reconstruction_rss\", Path(\"output\"), True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38ffbf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: DICOM to PNG ---\n",
    "\n",
    "def dicom_to_png(dicom_path, output_path=None, apply_windowing=True, normalize=True):\n",
    "    \"\"\"\n",
    "    Convert a DICOM file to PNG format.\n",
    "    Args:\n",
    "        dicom_path (str or Path): Path to the DICOM file\n",
    "        output_path (str or Path, optional): Output PNG file path. If None, uses same name as DICOM with .png extension\n",
    "        apply_windowing (bool): Whether to apply DICOM windowing (window center/width)\n",
    "        normalize (bool): Whether to normalize pixel values to 0-255 range\n",
    "    Returns:\n",
    "        str: Path to the saved PNG file\n",
    "    \"\"\"\n",
    "    dicom_path = Path(dicom_path)\n",
    "    if not dicom_path.exists():\n",
    "        raise FileNotFoundError(f\"DICOM file not found: {dicom_path}\")\n",
    "    ds = pydicom.dcmread(dicom_path)\n",
    "    pixel_array = ds.pixel_array\n",
    "    if ds.PixelRepresentation == 1:\n",
    "        pixel_array = pixel_array.astype(np.int16)\n",
    "    if hasattr(ds, 'RescaleSlope') and hasattr(ds, 'RescaleIntercept'):\n",
    "        pixel_array = pixel_array * ds.RescaleSlope + ds.RescaleIntercept\n",
    "    if apply_windowing and hasattr(ds, 'WindowCenter') and hasattr(ds, 'WindowWidth'):\n",
    "        window_center = float(ds.WindowCenter) if isinstance(ds.WindowCenter, (int, float, str)) else float(ds.WindowCenter[0])\n",
    "        window_width = float(ds.WindowWidth) if isinstance(ds.WindowWidth, (int, float, str)) else float(ds.WindowWidth[0])\n",
    "        window_min = window_center - window_width / 2\n",
    "        window_max = window_center + window_width / 2\n",
    "        pixel_array = np.clip(pixel_array, window_min, window_max)\n",
    "        pixel_array = (pixel_array - window_min) / (window_max - window_min) * 255\n",
    "    elif normalize:\n",
    "        pixel_min = np.min(pixel_array)\n",
    "        pixel_max = np.max(pixel_array)\n",
    "        if pixel_max > pixel_min:\n",
    "            pixel_array = (pixel_array - pixel_min) / (pixel_max - pixel_min) * 255\n",
    "        else:\n",
    "            pixel_array = np.zeros_like(pixel_array)\n",
    "    pixel_array = pixel_array.astype(np.uint8)\n",
    "    if len(pixel_array.shape) == 3:\n",
    "        print(f\"Multi-frame DICOM detected with {pixel_array.shape[0]} frames\")\n",
    "        output_dir = output_path.parent if output_path else dicom_path.parent\n",
    "        base_name = output_path.stem if output_path else dicom_path.stem\n",
    "        saved_files = []\n",
    "        for i, frame in enumerate(pixel_array):\n",
    "            frame_output = output_dir / f\"{base_name}_frame_{i:03d}.png\"\n",
    "            if len(frame.shape) == 2:\n",
    "                img = Image.fromarray(frame, mode='L')\n",
    "            else:\n",
    "                img = Image.fromarray(frame)\n",
    "            img.save(frame_output)\n",
    "            saved_files.append(str(frame_output))\n",
    "            print(f\"Saved frame {i}: {frame_output}\")\n",
    "        return saved_files\n",
    "    else:\n",
    "        if output_path is None:\n",
    "            output_path = dicom_path.with_suffix('.png')\n",
    "        else:\n",
    "            output_path = Path(output_path)\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        if len(pixel_array.shape) == 2:\n",
    "            img = Image.fromarray(pixel_array, mode='L')\n",
    "        else:\n",
    "            img = Image.fromarray(pixel_array)\n",
    "        img.save(output_path)\n",
    "        print(f\"Saved: {output_path}\")\n",
    "        return str(output_path)\n",
    "\n",
    "def process_directory(input_dir, output_dir=None, apply_windowing=True, normalize=True):\n",
    "    input_dir = Path(input_dir)\n",
    "    if output_dir is None:\n",
    "        output_dir = input_dir / \"png_output\"\n",
    "    else:\n",
    "        output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    dicom_extensions = ['.dcm', '.dicom', '.ima', '']\n",
    "    dicom_files = []\n",
    "    for ext in dicom_extensions:\n",
    "        if ext:\n",
    "            dicom_files.extend(input_dir.glob(f\"*{ext}\"))\n",
    "        else:\n",
    "            for file in input_dir.iterdir():\n",
    "                if file.is_file() and not file.suffix:\n",
    "                    try:\n",
    "                        pydicom.dcmread(file, stop_before_pixels=True)\n",
    "                        dicom_files.append(file)\n",
    "                    except:\n",
    "                        continue\n",
    "    if not dicom_files:\n",
    "        print(f\"No DICOM files found in {input_dir}\")\n",
    "        return\n",
    "    print(f\"Found {len(dicom_files)} DICOM files\")\n",
    "    for dicom_file in dicom_files:\n",
    "        try:\n",
    "            output_path = output_dir / f\"{dicom_file.stem}.png\"\n",
    "            dicom_to_png(dicom_file, output_path, apply_windowing, normalize)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {dicom_file}: {e}\")\n",
    "# Example usage\n",
    "# process_directory(\"output\", \"png-output\", True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f145ea0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '/mnt/f/datasets/demo_data/file1000002.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m fastmri_h5_path = Path(\u001b[33m\"\u001b[39m\u001b[33m/mnt/f/datasets/demo_data/file1000002.h5\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# Update path as needed\u001b[39;00m\n\u001b[32m      3\u001b[39m output_dicom_dir = Path(\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mfastmri_to_dicom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfastmri_h5_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreconstruction_rss\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dicom_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflip_up_down\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflip_left_right\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Step 2: Convert DICOM slices to PNG images\u001b[39;00m\n\u001b[32m      7\u001b[39m output_png_dir = Path(\u001b[33m\"\u001b[39m\u001b[33mpng-output\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mfastmri_to_dicom\u001b[39m\u001b[34m(filename, reconstruction_name, outfolder, flip_up_down, flip_left_right)\u001b[39m\n\u001b[32m      6\u001b[39m fileparts = os.path.splitext(filename.name)\n\u001b[32m      7\u001b[39m patientName = fileparts[\u001b[32m0\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m f = \u001b[43mh5py\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m outfolder:\n\u001b[32m     10\u001b[39m     outfolder = Path(patientName)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/JointWise/lib/python3.12/site-packages/h5py/_hl/files.py:564\u001b[39m, in \u001b[36mFile.__init__\u001b[39m\u001b[34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[39m\n\u001b[32m    555\u001b[39m     fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[32m    556\u001b[39m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[32m    557\u001b[39m                      alignment_threshold=alignment_threshold,\n\u001b[32m    558\u001b[39m                      alignment_interval=alignment_interval,\n\u001b[32m    559\u001b[39m                      meta_block_size=meta_block_size,\n\u001b[32m    560\u001b[39m                      **kwds)\n\u001b[32m    561\u001b[39m     fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[32m    562\u001b[39m                      fs_persist=fs_persist, fs_threshold=fs_threshold,\n\u001b[32m    563\u001b[39m                      fs_page_size=fs_page_size)\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m     fid = \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    567\u001b[39m     \u001b[38;5;28mself\u001b[39m._libver = libver\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/JointWise/lib/python3.12/site-packages/h5py/_hl/files.py:238\u001b[39m, in \u001b[36mmake_fid\u001b[39m\u001b[34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[39m\n\u001b[32m    236\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[32m    237\u001b[39m         flags |= h5f.ACC_SWMR_READ\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m     fid = \u001b[43mh5f\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mr+\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    240\u001b[39m     fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:56\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:57\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/h5f.pyx:102\u001b[39m, in \u001b[36mh5py.h5f.open\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/mnt/f/datasets/demo_data/file1000002.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# Step 1: Convert FastMRI HDF5 to DICOM slices\n",
    "fastmri_h5_path = Path(\"/mnt/f/datasets/demo_data/file1000002.h5\")  # Update path as needed\n",
    "output_dicom_dir = Path(\"output\")\n",
    "fastmri_to_dicom(fastmri_h5_path, \"reconstruction_rss\", output_dicom_dir, flip_up_down=True, flip_left_right=False)\n",
    "\n",
    "# Step 2: Convert DICOM slices to PNG images\n",
    "output_png_dir = Path(\"png-output\")\n",
    "process_directory(output_dicom_dir, output_png_dir, apply_windowing=True, normalize=True)\n",
    "\n",
    "print(\"Pipeline complete. DICOM files are in 'output/', PNG files are in 'png-output/'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89a65f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Set deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Environment setup complete.\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c501e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process annotations from knee.csv\n",
    "class DataProcessor:\n",
    "    def __init__(self, csv_path, png_dir):\n",
    "        self.csv_path = csv_path\n",
    "        self.png_dir = Path(png_dir)\n",
    "        self.df = None\n",
    "        self.subject_labels = {}\n",
    "        \n",
    "    def load_annotations(self):\n",
    "        \"\"\"Load and process knee annotations\"\"\"\n",
    "        self.df = pd.read_csv(self.csv_path)\n",
    "        print(f\"Loaded {len(self.df)} annotations\")\n",
    "        print(f\"Unique files: {self.df['file'].nunique()}\")\n",
    "        print(f\"Label distribution:\")\n",
    "        print(self.df['label'].value_counts())\n",
    "        return self.df\n",
    "    \n",
    "    def create_target_labels(self):\n",
    "        \"\"\"Create target labels: ACL tear, Meniscus tear, Neither\"\"\"\n",
    "        # Map detailed labels to our target classes\n",
    "        acl_keywords = ['ACL', 'Anterior Cruciate', 'Anterior Cruciate Ligament', 'ACL High Grade Sprain', 'ACL Low Grade sprain']\n",
    "        meniscus_keywords = ['Meniscus', 'Meniscus Tear']\n",
    "        \n",
    "        subject_conditions = {}\n",
    "        \n",
    "        for file_id in self.df['file'].unique():\n",
    "            file_data = self.df[self.df['file'] == file_id]\n",
    "            labels = file_data['label'].tolist()\n",
    "            \n",
    "            has_acl = any(any(keyword.lower() in label.lower() for keyword in acl_keywords) for label in labels)\n",
    "            has_meniscus = any(any(keyword.lower() in label.lower() for keyword in meniscus_keywords) for label in labels)\n",
    "            \n",
    "            if has_acl and has_meniscus:\n",
    "                subject_conditions[file_id] = 'Both'  # We'll handle this case\n",
    "            elif has_acl:\n",
    "                subject_conditions[file_id] = 'ACL_tear'\n",
    "            elif has_meniscus:\n",
    "                subject_conditions[file_id] = 'Meniscus_tear'\n",
    "            else:\n",
    "                subject_conditions[file_id] = 'Neither'\n",
    "        \n",
    "        self.subject_labels = subject_conditions\n",
    "        print(\"\\nSubject-level label distribution:\")\n",
    "        label_counts = pd.Series(list(subject_conditions.values())).value_counts()\n",
    "        print(label_counts)\n",
    "        \n",
    "        return subject_conditions\n",
    "    \n",
    "    def get_bounding_boxes(self, file_id, slice_num):\n",
    "        \"\"\"Get bounding boxes for a specific file and slice\"\"\"\n",
    "        slice_data = self.df[(self.df['file'] == file_id) & (self.df['slice'] == slice_num)]\n",
    "        boxes = []\n",
    "        for _, row in slice_data.iterrows():\n",
    "            boxes.append({\n",
    "                'x': row['x'], 'y': row['y'], \n",
    "                'width': row['width'], 'height': row['height'],\n",
    "                'label': row['label']\n",
    "            })\n",
    "        return boxes\n",
    "    \n",
    "    def get_available_images(self):\n",
    "        \"\"\"Get list of available PNG images with their labels\"\"\"\n",
    "        available_images = []\n",
    "        \n",
    "        for png_file in self.png_dir.glob('*.png'):\n",
    "            # Extract file ID and slice from filename (e.g., file1000002_000.png)\n",
    "            filename = png_file.stem\n",
    "            parts = filename.split('_')\n",
    "            if len(parts) >= 2:\n",
    "                file_id = '_'.join(parts[:-1])  # Everything except last part\n",
    "                slice_num = int(parts[-1])  # Last part is slice number\n",
    "                \n",
    "                if file_id in self.subject_labels:\n",
    "                    available_images.append({\n",
    "                        'path': str(png_file),\n",
    "                        'file_id': file_id,\n",
    "                        'slice': slice_num,\n",
    "                        'label': self.subject_labels[file_id]\n",
    "                    })\n",
    "        \n",
    "        print(f\"\\nFound {len(available_images)} available images\")\n",
    "        return available_images\n",
    "\n",
    "# Initialize data processor\n",
    "data_processor = DataProcessor('knee.csv', 'png-output')\n",
    "annotations = data_processor.load_annotations()\n",
    "subject_labels = data_processor.create_target_labels()\n",
    "available_images = data_processor.get_available_images()\n",
    "\n",
    "print(f\"\\nReady to process {len(available_images)} images from {len(subject_labels)} subjects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0607c18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation for MRI Scans using Albumentations\n",
    "class MRIAugmentation:\n",
    "    def __init__(self, image_size=(224, 224)):\n",
    "        self.image_size = image_size\n",
    "        \n",
    "    def get_train_augmentation(self):\n",
    "        \"\"\"Augmentation pipeline for training data - appropriate for MRI\"\"\"\n",
    "        return A.Compose([\n",
    "            A.Resize(self.image_size[0], self.image_size[1], always_apply=True),\n",
    "            \n",
    "            # Geometric transformations (conservative for medical images)\n",
    "            A.HorizontalFlip(p=0.5),  # Anatomically valid\n",
    "            A.Rotate(limit=10, p=0.3),  # Small rotations only\n",
    "            A.ShiftScaleRotate(\n",
    "                shift_limit=0.05, \n",
    "                scale_limit=0.05, \n",
    "                rotate_limit=5, \n",
    "                p=0.3\n",
    "            ),\n",
    "            \n",
    "            # Intensity transformations (important for MRI)\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=0.1, \n",
    "                contrast_limit=0.1, \n",
    "                p=0.3\n",
    "            ),\n",
    "            A.RandomGamma(gamma_limit=(90, 110), p=0.2),\n",
    "            \n",
    "            # Noise and blur (simulate acquisition variations)\n",
    "            A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),\n",
    "            A.GaussianBlur(blur_limit=(1, 3), p=0.1),\n",
    "            \n",
    "            # Elastic deformation (subtle tissue deformation)\n",
    "            A.ElasticTransform(\n",
    "                alpha=30,\n",
    "                sigma=5,\n",
    "                alpha_affine=3,\n",
    "                p=0.1\n",
    "            ),\n",
    "            \n",
    "            # Normalization\n",
    "            A.Normalize(\n",
    "                mean=[0.485],  # Grayscale\n",
    "                std=[0.229],\n",
    "                max_pixel_value=255.0\n",
    "            )\n",
    "        ])\n",
    "    \n",
    "    def get_val_augmentation(self):\n",
    "        \"\"\"Augmentation pipeline for validation/test data\"\"\"\n",
    "        return A.Compose([\n",
    "            A.Resize(self.image_size[0], self.image_size[1], always_apply=True),\n",
    "            A.Normalize(\n",
    "                mean=[0.485],\n",
    "                std=[0.229],\n",
    "                max_pixel_value=255.0\n",
    "            )\n",
    "        ])\n",
    "\n",
    "# Initialize augmentation\n",
    "augmentation = MRIAugmentation(image_size=(224, 224))\n",
    "train_transform = augmentation.get_train_augmentation()\n",
    "val_transform = augmentation.get_val_augmentation()\n",
    "\n",
    "print(\"MRI-specific augmentation pipeline created.\")\n",
    "print(\"Train augmentations: Flip, Rotate, Brightness/Contrast, Noise, Blur\")\n",
    "print(\"Validation augmentations: Resize, Normalize only\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a76844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject-level Data Splitting and Balancing\n",
    "class SubjectLevelSplitter:\n",
    "    def __init__(self, available_images, test_size=0.2, val_size=0.2, random_state=42):\n",
    "        self.available_images = available_images\n",
    "        self.test_size = test_size\n",
    "        self.val_size = val_size\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def split_subjects(self):\n",
    "        \"\"\"Split data at subject level to prevent data leakage\"\"\"\n",
    "        # Group images by subject\n",
    "        subject_data = {}\n",
    "        for img_info in self.available_images:\n",
    "            file_id = img_info['file_id']\n",
    "            if file_id not in subject_data:\n",
    "                subject_data[file_id] = []\n",
    "            subject_data[file_id].append(img_info)\n",
    "        \n",
    "        # Get unique subjects and their labels\n",
    "        subjects = list(subject_data.keys())\n",
    "        subject_labels_list = [subject_data[subj][0]['label'] for subj in subjects]\n",
    "        \n",
    "        print(f\"Total subjects: {len(subjects)}\")\n",
    "        print(f\"Label distribution across subjects:\")\n",
    "        print(pd.Series(subject_labels_list).value_counts())\n",
    "        \n",
    "        # First split: train+val vs test\n",
    "        train_val_subjects, test_subjects = train_test_split(\n",
    "            subjects, \n",
    "            test_size=self.test_size, \n",
    "            stratify=subject_labels_list, \n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "        # Second split: train vs val\n",
    "        train_val_labels = [subject_data[subj][0]['label'] for subj in train_val_subjects]\n",
    "        train_subjects, val_subjects = train_test_split(\n",
    "            train_val_subjects,\n",
    "            test_size=self.val_size / (1 - self.test_size),  # Adjust for already removed test set\n",
    "            stratify=train_val_labels,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "        # Create final datasets\n",
    "        train_data = []\n",
    "        val_data = []\n",
    "        test_data = []\n",
    "        \n",
    "        for subj in train_subjects:\n",
    "            train_data.extend(subject_data[subj])\n",
    "        for subj in val_subjects:\n",
    "            val_data.extend(subject_data[subj])\n",
    "        for subj in test_subjects:\n",
    "            test_data.extend(subject_data[subj])\n",
    "        \n",
    "        print(f\"\\nData split completed:\")\n",
    "        print(f\"Train: {len(train_data)} images from {len(train_subjects)} subjects\")\n",
    "        print(f\"Val: {len(val_data)} images from {len(val_subjects)} subjects\")\n",
    "        print(f\"Test: {len(test_data)} images from {len(test_subjects)} subjects\")\n",
    "        \n",
    "        # Print label distribution for each split\n",
    "        for split_name, split_data in [('Train', train_data), ('Val', val_data), ('Test', test_data)]:\n",
    "            labels = [item['label'] for item in split_data]\n",
    "            print(f\"\\n{split_name} label distribution:\")\n",
    "            print(pd.Series(labels).value_counts())\n",
    "        \n",
    "        return train_data, val_data, test_data\n",
    "    \n",
    "    def balance_classes(self, data, method='undersample'):\n",
    "        \"\"\"Balance classes in the dataset\"\"\"\n",
    "        # Group by label\n",
    "        label_groups = {}\n",
    "        for item in data:\n",
    "            label = item['label']\n",
    "            if label not in label_groups:\n",
    "                label_groups[label] = []\n",
    "            label_groups[label].append(item)\n",
    "        \n",
    "        print(f\"\\nClass distribution before balancing:\")\n",
    "        for label, items in label_groups.items():\n",
    "            print(f\"{label}: {len(items)}\")\n",
    "        \n",
    "        if method == 'undersample':\n",
    "            # Undersample to the minority class size\n",
    "            min_size = min(len(items) for items in label_groups.values())\n",
    "            balanced_data = []\n",
    "            \n",
    "            for label, items in label_groups.items():\n",
    "                np.random.shuffle(items)\n",
    "                balanced_data.extend(items[:min_size])\n",
    "                \n",
    "        elif method == 'oversample':\n",
    "            # Oversample to the majority class size\n",
    "            max_size = max(len(items) for items in label_groups.values())\n",
    "            balanced_data = []\n",
    "            \n",
    "            for label, items in label_groups.items():\n",
    "                # Repeat items to reach max_size\n",
    "                multiplier = max_size // len(items)\n",
    "                remainder = max_size % len(items)\n",
    "                \n",
    "                extended_items = items * multiplier\n",
    "                if remainder > 0:\n",
    "                    np.random.shuffle(items)\n",
    "                    extended_items.extend(items[:remainder])\n",
    "                \n",
    "                balanced_data.extend(extended_items)\n",
    "        \n",
    "        np.random.shuffle(balanced_data)\n",
    "        \n",
    "        print(f\"\\nClass distribution after {method}:\")\n",
    "        balanced_labels = [item['label'] for item in balanced_data]\n",
    "        print(pd.Series(balanced_labels).value_counts())\n",
    "        \n",
    "        return balanced_data\n",
    "\n",
    "# Perform subject-level splitting\n",
    "splitter = SubjectLevelSplitter(available_images, test_size=0.2, val_size=0.2)\n",
    "train_data, val_data, test_data = splitter.split_subjects()\n",
    "\n",
    "# Balance training data (optional - you can choose undersample or oversample)\n",
    "train_data_balanced = splitter.balance_classes(train_data, method='oversample')\n",
    "\n",
    "print(f\"\\nFinal dataset sizes:\")\n",
    "print(f\"Balanced Train: {len(train_data_balanced)}\")\n",
    "print(f\"Val: {len(val_data)}\")\n",
    "print(f\"Test: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73044cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Dataset for Efficient Loading\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, data, transform=None, num_classes=3):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Create label encoder\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        all_labels = [item['label'] for item in data]\n",
    "        self.label_encoder.fit(all_labels)\n",
    "        \n",
    "        # Pre-encode all labels\n",
    "        self.encoded_labels = self.label_encoder.transform(all_labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(item['path'], cv2.IMREAD_GRAYSCALE)\n",
    "        if image is None:\n",
    "            # Create dummy image if loading fails\n",
    "            print(f\"Warning: Could not load image {item['path']}\")\n",
    "            image = np.zeros((224, 224), dtype=np.uint8)\n",
    "        \n",
    "        # Convert to RGB (repeat grayscale across 3 channels)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "        \n",
    "        # Apply augmentation\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image_rgb)\n",
    "            image_rgb = augmented['image']\n",
    "        \n",
    "        # Ensure correct format for PyTorch\n",
    "        if isinstance(image_rgb, np.ndarray):\n",
    "            if len(image_rgb.shape) == 3 and image_rgb.shape[2] == 3:\n",
    "                # Convert from HWC to CHW format for PyTorch\n",
    "                image_tensor = torch.from_numpy(image_rgb.transpose(2, 0, 1)).float()\n",
    "            else:\n",
    "                # Fallback: normalize and convert\n",
    "                image_rgb = image_rgb.astype(np.float32) / 255.0\n",
    "                if len(image_rgb.shape) == 2:\n",
    "                    image_rgb = np.stack([image_rgb] * 3, axis=0)  # CHW format\n",
    "                else:\n",
    "                    image_rgb = image_rgb.transpose(2, 0, 1)  # HWC to CHW\n",
    "                image_tensor = torch.from_numpy(image_rgb).float()\n",
    "        else:\n",
    "            # Already a tensor from albumentations\n",
    "            image_tensor = image_rgb\n",
    "        \n",
    "        # Get label\n",
    "        label = self.encoded_labels[idx]\n",
    "        \n",
    "        return image_tensor, label\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return [item['label'] for item in self.data]\n",
    "    \n",
    "    def get_class_weights(self):\n",
    "        labels = self.get_labels()\n",
    "        label_encoded = self.label_encoder.transform(labels)\n",
    "        class_weights = compute_class_weight(\n",
    "            'balanced',\n",
    "            classes=np.unique(label_encoded),\n",
    "            y=label_encoded\n",
    "        )\n",
    "        return torch.FloatTensor(class_weights).to(device)\n",
    "    \n",
    "    def get_weighted_sampler(self):\n",
    "        \"\"\"Create weighted sampler for balanced training\"\"\"\n",
    "        labels = self.encoded_labels\n",
    "        class_counts = np.bincount(labels)\n",
    "        class_weights = 1.0 / class_counts\n",
    "        sample_weights = class_weights[labels]\n",
    "        \n",
    "        return WeightedRandomSampler(\n",
    "            weights=sample_weights,\n",
    "            num_samples=len(sample_weights),\n",
    "            replacement=True\n",
    "        )\n",
    "\n",
    "# Update augmentation to work with PyTorch\n",
    "class MRIAugmentationPyTorch:\n",
    "    def __init__(self, image_size=(224, 224)):\n",
    "        self.image_size = image_size\n",
    "        \n",
    "    def get_train_augmentation(self):\n",
    "        \"\"\"Augmentation pipeline for training data - appropriate for MRI\"\"\"\n",
    "        return A.Compose([\n",
    "            A.Resize(self.image_size[0], self.image_size[1], always_apply=True),\n",
    "            \n",
    "            # Geometric transformations (conservative for medical images)\n",
    "            A.HorizontalFlip(p=0.5),  # Anatomically valid\n",
    "            A.Rotate(limit=10, p=0.3),  # Small rotations only\n",
    "            A.ShiftScaleRotate(\n",
    "                shift_limit=0.05, \n",
    "                scale_limit=0.05, \n",
    "                rotate_limit=5, \n",
    "                p=0.3\n",
    "            ),\n",
    "            \n",
    "            # Intensity transformations (important for MRI)\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=0.1, \n",
    "                contrast_limit=0.1, \n",
    "                p=0.3\n",
    "            ),\n",
    "            A.RandomGamma(gamma_limit=(90, 110), p=0.2),\n",
    "            \n",
    "            # Noise and blur (simulate acquisition variations)\n",
    "            A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),\n",
    "            A.GaussianBlur(blur_limit=(1, 3), p=0.1),\n",
    "            \n",
    "            # Elastic deformation (subtle tissue deformation)\n",
    "            A.ElasticTransform(\n",
    "                alpha=30,\n",
    "                sigma=5,\n",
    "                alpha_affine=3,\n",
    "                p=0.1\n",
    "            ),\n",
    "            \n",
    "            # Normalization for PyTorch\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],  # ImageNet means for RGB\n",
    "                std=[0.229, 0.224, 0.225],   # ImageNet stds for RGB\n",
    "                max_pixel_value=255.0\n",
    "            ),\n",
    "            ToTensorV2()  # Convert to PyTorch tensor\n",
    "        ])\n",
    "    \n",
    "    def get_val_augmentation(self):\n",
    "        \"\"\"Augmentation pipeline for validation/test data\"\"\"\n",
    "        return A.Compose([\n",
    "            A.Resize(self.image_size[0], self.image_size[1], always_apply=True),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "                max_pixel_value=255.0\n",
    "            ),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "\n",
    "# Create PyTorch datasets and dataloaders\n",
    "print(\"Creating PyTorch datasets and dataloaders...\")\n",
    "\n",
    "# Initialize augmentation\n",
    "augmentation = MRIAugmentationPyTorch(image_size=(224, 224))\n",
    "train_transform = augmentation.get_train_augmentation()\n",
    "val_transform = augmentation.get_val_augmentation()\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = MRIDataset(train_data_balanced, transform=train_transform)\n",
    "val_dataset = MRIDataset(val_data, transform=val_transform)\n",
    "test_dataset = MRIDataset(test_data, transform=val_transform)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 16\n",
    "\n",
    "# Use weighted sampler for balanced training\n",
    "train_sampler = train_dataset.get_weighted_sampler()\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    sampler=train_sampler,\n",
    "    num_workers=4,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "# Get class weights\n",
    "class_weights = train_dataset.get_class_weights()\n",
    "\n",
    "print(f\"Train loader: {len(train_loader)} batches\")\n",
    "print(f\"Val loader: {len(val_loader)} batches\")\n",
    "print(f\"Test loader: {len(test_loader)} batches\")\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "print(f\"Label encoding: {dict(zip(train_dataset.label_encoder.classes_, range(len(train_dataset.label_encoder.classes_))))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd64d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Model Architectures in PyTorch\n",
    "class BaseModelBuilder:\n",
    "    def __init__(self, num_classes=3):\n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "    def build_resnext50(self, dropout_rate=0.5, freeze_backbone=True):\n",
    "        \"\"\"Build ResNeXt-50 model\"\"\"\n",
    "        model = models.resnext50_32x4d(pretrained=True)\n",
    "        \n",
    "        # Freeze backbone if specified\n",
    "        if freeze_backbone:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Replace classifier\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, self.num_classes)\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def build_densenet201(self, dropout_rate=0.5, freeze_backbone=True):\n",
    "        \"\"\"Build DenseNet-201 model\"\"\"\n",
    "        model = models.densenet201(pretrained=True)\n",
    "        \n",
    "        # Freeze backbone if specified\n",
    "        if freeze_backbone:\n",
    "            for param in model.features.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Replace classifier\n",
    "        num_features = model.classifier.in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, self.num_classes)\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def build_efficientnet_b7(self, dropout_rate=0.5, freeze_backbone=True):\n",
    "        \"\"\"Build EfficientNet-B7 model\"\"\"\n",
    "        model = models.efficientnet_b7(pretrained=True)\n",
    "        \n",
    "        # Freeze backbone if specified\n",
    "        if freeze_backbone:\n",
    "            for param in model.features.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Replace classifier\n",
    "        num_features = model.classifier[1].in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(num_features, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, self.num_classes)\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def build_xception(self, dropout_rate=0.5, freeze_backbone=True):\n",
    "        \"\"\"Build Xception model\"\"\"\n",
    "        model = timm.create_model('xception41', pretrained=True)\n",
    "        \n",
    "        # Freeze backbone if specified\n",
    "        if freeze_backbone:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "            # Unfreeze classifier head\n",
    "            for param in model.classifier.parameters():\n",
    "                param.requires_grad = True\n",
    "        \n",
    "        # Replace classifier head\n",
    "        num_features = model.classifier.in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, self.num_classes)\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def get_model_by_name(self, model_name, **kwargs):\n",
    "        \"\"\"Get model by name\"\"\"\n",
    "        if model_name == 'resnext50':\n",
    "            return self.build_resnext50(**kwargs)\n",
    "        elif model_name == 'densenet201':\n",
    "            return self.build_densenet201(**kwargs)\n",
    "        elif model_name == 'efficientnet_b7':\n",
    "            return self.build_efficientnet_b7(**kwargs)\n",
    "        elif model_name == 'xception':\n",
    "            return self.build_xception(**kwargs)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "\n",
    "class PyTorchTrainer:\n",
    "    def __init__(self, model, device, class_weights=None):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.class_weights = class_weights\n",
    "        \n",
    "        # Loss function with class weights\n",
    "        if class_weights is not None:\n",
    "            self.criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        else:\n",
    "            self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.training_history = {\n",
    "            'train_loss': [], 'train_acc': [],\n",
    "            'val_loss': [], 'val_acc': []\n",
    "        }\n",
    "    \n",
    "    def train_epoch(self, train_loader, optimizer):\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        train_bar = tqdm(train_loader, desc='Training')\n",
    "        for batch_idx, (data, target) in enumerate(train_bar):\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            loss = self.criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_bar.set_postfix({\n",
    "                'Loss': f'{running_loss/(batch_idx+1):.4f}',\n",
    "                'Acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = correct / total\n",
    "        \n",
    "        return epoch_loss, epoch_acc\n",
    "    \n",
    "    def validate_epoch(self, val_loader):\n",
    "        \"\"\"Validate for one epoch\"\"\"\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self.model(data)\n",
    "                loss = self.criterion(output, target)\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(val_loader)\n",
    "        epoch_acc = correct / total\n",
    "        \n",
    "        return epoch_loss, epoch_acc\n",
    "    \n",
    "    def train(self, train_loader, val_loader, epochs=50, learning_rate=1e-4,\n",
    "              patience=10, save_path=None):\n",
    "        \"\"\"Full training loop\"\"\"\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, \n",
    "                                     patience=5, verbose=True)\n",
    "        \n",
    "        best_val_acc = 0.0\n",
    "        patience_counter = 0\n",
    "        \n",
    "        print(f\"Starting training for {epochs} epochs...\")\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "            print(\"-\" * 30)\n",
    "            \n",
    "            # Train\n",
    "            train_loss, train_acc = self.train_epoch(train_loader, optimizer)\n",
    "            \n",
    "            # Validate\n",
    "            val_loss, val_acc = self.validate_epoch(val_loader)\n",
    "            \n",
    "            # Update learning rate\n",
    "            scheduler.step(val_acc)\n",
    "            \n",
    "            # Save history\n",
    "            self.training_history['train_loss'].append(train_loss)\n",
    "            self.training_history['train_acc'].append(train_acc)\n",
    "            self.training_history['val_loss'].append(val_loss)\n",
    "            self.training_history['val_acc'].append(val_acc)\n",
    "            \n",
    "            print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "            print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "            \n",
    "            # Early stopping and model saving\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                if save_path:\n",
    "                    torch.save(self.model.state_dict(), save_path)\n",
    "                    print(f\"Model saved to {save_path}\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                \n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "                break\n",
    "        \n",
    "        print(f\"\\nTraining completed. Best validation accuracy: {best_val_acc:.4f}\")\n",
    "        return self.training_history\n",
    "\n",
    "# Initialize model builder\n",
    "model_builder = BaseModelBuilder(num_classes=3)\n",
    "\n",
    "print(\"PyTorch model architectures defined:\")\n",
    "print(\"- ResNeXt-50 (32x4d)\")\n",
    "print(\"- DenseNet-201\")\n",
    "print(\"- EfficientNet-B7\")\n",
    "print(\"- Xception-41\")\n",
    "print(\"\\nAll models use transfer learning with ImageNet pretrained weights.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295dd3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genetic Algorithm for Hyperparameter Optimization (PyTorch)\n",
    "class GeneticOptimizerPyTorch:\n",
    "    def __init__(self, model_name, model_builder, train_loader, val_loader, device):\n",
    "        self.model_name = model_name\n",
    "        self.model_builder = model_builder\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = device\n",
    "        self.setup_deap()\n",
    "    \n",
    "    def setup_deap(self):\n",
    "        \"\"\"Setup DEAP genetic algorithm framework\"\"\"\n",
    "        # Create fitness class (maximize validation accuracy)\n",
    "        if hasattr(creator, 'FitnessMax'):\n",
    "            del creator.FitnessMax\n",
    "        if hasattr(creator, 'Individual'):\n",
    "            del creator.Individual\n",
    "            \n",
    "        creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "        creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "        \n",
    "        self.toolbox = base.Toolbox()\n",
    "        \n",
    "        # Hyperparameter ranges\n",
    "        self.param_ranges = {\n",
    "            'learning_rate': (1e-5, 1e-2),\n",
    "            'dropout_rate': (0.2, 0.7),\n",
    "            'weight_decay': (1e-6, 1e-3),\n",
    "            'batch_size': [8, 16, 32]  # Limited options for memory\n",
    "        }\n",
    "        \n",
    "        # Register genetic operators\n",
    "        self.toolbox.register(\"learning_rate\", random.uniform, *self.param_ranges['learning_rate'])\n",
    "        self.toolbox.register(\"dropout_rate\", random.uniform, *self.param_ranges['dropout_rate'])\n",
    "        self.toolbox.register(\"weight_decay\", random.uniform, *self.param_ranges['weight_decay'])\n",
    "        self.toolbox.register(\"batch_size\", random.choice, self.param_ranges['batch_size'])\n",
    "        \n",
    "        self.toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                            (self.toolbox.learning_rate, self.toolbox.dropout_rate,\n",
    "                             self.toolbox.weight_decay, self.toolbox.batch_size), n=1)\n",
    "        \n",
    "        self.toolbox.register(\"population\", tools.initRepeat, list, self.toolbox.individual)\n",
    "        self.toolbox.register(\"evaluate\", self.evaluate_individual)\n",
    "        self.toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "        self.toolbox.register(\"mutate\", self.mutate_individual, indpb=0.2)\n",
    "        self.toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "    \n",
    "    def evaluate_individual(self, individual):\n",
    "        \"\"\"Evaluate an individual (set of hyperparameters)\"\"\"\n",
    "        learning_rate, dropout_rate, weight_decay, batch_size = individual\n",
    "        \n",
    "        try:\n",
    "            # Build model with current hyperparameters\n",
    "            model = self.model_builder.get_model_by_name(\n",
    "                self.model_name, \n",
    "                dropout_rate=dropout_rate, \n",
    "                freeze_backbone=True\n",
    "            )\n",
    "            \n",
    "            # Create trainer\n",
    "            trainer = PyTorchTrainer(model, self.device, class_weights)\n",
    "            \n",
    "            # Create optimizer\n",
    "            optimizer = optim.Adam(\n",
    "                model.parameters(), \n",
    "                lr=learning_rate, \n",
    "                weight_decay=weight_decay\n",
    "            )\n",
    "            \n",
    "            # Quick training for evaluation (reduced epochs)\n",
    "            model.train()\n",
    "            total_correct = 0\n",
    "            total_samples = 0\n",
    "            \n",
    "            # Train for a few batches only\n",
    "            for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "                if batch_idx >= 5:  # Limit to 5 batches for speed\n",
    "                    break\n",
    "                    \n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = trainer.criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            # Quick validation\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (data, target) in enumerate(self.val_loader):\n",
    "                    if batch_idx >= 3:  # Limit validation batches\n",
    "                        break\n",
    "                        \n",
    "                    data, target = data.to(self.device), target.to(self.device)\n",
    "                    output = model(data)\n",
    "                    _, predicted = torch.max(output.data, 1)\n",
    "                    total_samples += target.size(0)\n",
    "                    total_correct += (predicted == target).sum().item()\n",
    "            \n",
    "            val_accuracy = total_correct / total_samples if total_samples > 0 else 0.0\n",
    "            \n",
    "            # Clean up GPU memory\n",
    "            del model, trainer, optimizer\n",
    "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "            \n",
    "            return (val_accuracy,)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating individual: {e}\")\n",
    "            # Clean up on error\n",
    "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "            return (0.0,)\n",
    "    \n",
    "    def mutate_individual(self, individual, indpb):\n",
    "        \"\"\"Mutate an individual\"\"\"\n",
    "        if random.random() < indpb:\n",
    "            individual[0] = random.uniform(*self.param_ranges['learning_rate'])\n",
    "        if random.random() < indpb:\n",
    "            individual[1] = random.uniform(*self.param_ranges['dropout_rate'])\n",
    "        if random.random() < indpb:\n",
    "            individual[2] = random.uniform(*self.param_ranges['weight_decay'])\n",
    "        if random.random() < indpb:\n",
    "            individual[3] = random.choice(self.param_ranges['batch_size'])\n",
    "        \n",
    "        return individual,\n",
    "    \n",
    "    def optimize(self, population_size=8, generations=3):\n",
    "        \"\"\"Run genetic algorithm optimization\"\"\"\n",
    "        print(f\"Starting genetic optimization for {self.model_name}...\")\n",
    "        print(f\"Population size: {population_size}, Generations: {generations}\")\n",
    "        \n",
    "        # Create initial population\n",
    "        population = self.toolbox.population(n=population_size)\n",
    "        \n",
    "        # Track statistics\n",
    "        stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "        stats.register(\"avg\", np.mean)\n",
    "        stats.register(\"min\", np.min)\n",
    "        stats.register(\"max\", np.max)\n",
    "        \n",
    "        # Run genetic algorithm\n",
    "        population, logbook = algorithms.eaSimple(\n",
    "            population, self.toolbox,\n",
    "            cxpb=0.7,\n",
    "            mutpb=0.3,\n",
    "            ngen=generations,\n",
    "            stats=stats,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # Get best individual\n",
    "        best_individual = tools.selBest(population, 1)[0]\n",
    "        best_params = {\n",
    "            'learning_rate': best_individual[0],\n",
    "            'dropout_rate': best_individual[1],\n",
    "            'weight_decay': best_individual[2],\n",
    "            'batch_size': int(best_individual[3]),\n",
    "            'fitness': best_individual.fitness.values[0]\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nBest parameters for {self.model_name}:\")\n",
    "        for param, value in best_params.items():\n",
    "            print(f\"{param}: {value}\")\n",
    "        \n",
    "        return best_params, logbook\n",
    "\n",
    "print(\"PyTorch Genetic Algorithm optimizer defined.\")\n",
    "print(\"Ready to optimize hyperparameters for each base model.\")\n",
    "print(\"Note: Optimization is faster but less thorough due to PyTorch memory management.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a85a970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Base Models with Optimized Hyperparameters (PyTorch)\n",
    "class PyTorchModelTrainer:\n",
    "    def __init__(self, model_builder, train_loader, val_loader, test_loader, class_weights, device):\n",
    "        self.model_builder = model_builder\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.class_weights = class_weights\n",
    "        self.device = device\n",
    "        self.trained_models = {}\n",
    "        self.training_histories = {}\n",
    "        self.best_params = {}\n",
    "    \n",
    "    def optimize_and_train_model(self, model_name, optimize_hyperparams=True, \n",
    "                                default_params=None, epochs=50):\n",
    "        \"\"\"Optimize hyperparameters and train a model\"\"\"\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training {model_name.upper()}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        if optimize_hyperparams:\n",
    "            # Genetic algorithm optimization\n",
    "            optimizer = GeneticOptimizerPyTorch(\n",
    "                model_name, self.model_builder, \n",
    "                self.train_loader, self.val_loader, self.device\n",
    "            )\n",
    "            best_params, _ = optimizer.optimize(population_size=4, generations=2)  # Reduced for demo\n",
    "            self.best_params[model_name] = best_params\n",
    "        else:\n",
    "            # Use default parameters\n",
    "            best_params = default_params or {\n",
    "                'learning_rate': 1e-4,\n",
    "                'dropout_rate': 0.5,\n",
    "                'weight_decay': 1e-4,\n",
    "                'batch_size': 16\n",
    "            }\n",
    "            self.best_params[model_name] = best_params\n",
    "        \n",
    "        print(f\"\\nUsing parameters: {best_params}\")\n",
    "        \n",
    "        # Build model with best parameters\n",
    "        model = self.model_builder.get_model_by_name(\n",
    "            model_name, \n",
    "            dropout_rate=best_params['dropout_rate'], \n",
    "            freeze_backbone=True\n",
    "        )\n",
    "        \n",
    "        print(f\"Model architecture for {model_name}:\")\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f\"Total parameters: {total_params:,}\")\n",
    "        print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "        \n",
    "        # Phase 1: Train with frozen backbone\n",
    "        print(\"\\nPhase 1: Training with frozen backbone...\")\n",
    "        trainer = PyTorchTrainer(model, self.device, self.class_weights)\n",
    "        \n",
    "        history1 = trainer.train(\n",
    "            self.train_loader, self.val_loader,\n",
    "            epochs=epochs // 2,\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            save_path=f'best_{model_name}_phase1.pth'\n",
    "        )\n",
    "        \n",
    "        # Phase 2: Fine-tune with unfrozen backbone\n",
    "        print(\"\\nPhase 2: Fine-tuning with unfrozen backbone...\")\n",
    "        \n",
    "        # Unfreeze backbone gradually\n",
    "        if model_name == 'resnext50':\n",
    "            # Unfreeze last few layers\n",
    "            for param in model.layer4.parameters():\n",
    "                param.requires_grad = True\n",
    "        elif model_name == 'densenet201':\n",
    "            # Unfreeze last dense block\n",
    "            for param in model.features.denseblock4.parameters():\n",
    "                param.requires_grad = True\n",
    "        elif model_name == 'efficientnet_b7':\n",
    "            # Unfreeze last few blocks\n",
    "            for param in list(model.features.children())[-3:][0].parameters():\n",
    "                param.requires_grad = True\n",
    "        elif model_name == 'xception':\n",
    "            # Unfreeze last few transformer blocks\n",
    "            for param in model.encoder.layers[-2:].parameters():\n",
    "                param.requires_grad = True\n",
    "        \n",
    "        # Create new trainer with lower learning rate\n",
    "        trainer_ft = PyTorchTrainer(model, self.device, self.class_weights)\n",
    "        \n",
    "        history2 = trainer_ft.train(\n",
    "            self.train_loader, self.val_loader,\n",
    "            epochs=epochs // 2,\n",
    "            learning_rate=best_params['learning_rate'] / 10,  # Lower LR for fine-tuning\n",
    "            save_path=f'best_{model_name}_final.pth'\n",
    "        )\n",
    "        \n",
    "        # Combine histories\n",
    "        combined_history = {}\n",
    "        for key in history1.keys():\n",
    "            combined_history[key] = history1[key] + history2[key]\n",
    "        \n",
    "        # Store model and history\n",
    "        self.trained_models[model_name] = model\n",
    "        self.training_histories[model_name] = combined_history\n",
    "        \n",
    "        print(f\"\\n{model_name.upper()} training completed!\")\n",
    "        \n",
    "        return model, combined_history\n",
    "    \n",
    "    def train_all_models(self, optimize_hyperparams=False, epochs=30):\n",
    "        \"\"\"Train all base models\"\"\"\n",
    "        model_names = ['resnext50', 'densenet201', 'efficientnet_b7', 'xception']\n",
    "        \n",
    "        # Default parameters for quick training (if not optimizing)\n",
    "        default_params = {\n",
    "            'resnext50': {'learning_rate': 1e-4, 'dropout_rate': 0.4, 'weight_decay': 1e-4, 'batch_size': 16},\n",
    "            'densenet201': {'learning_rate': 1e-4, 'dropout_rate': 0.6, 'weight_decay': 1e-4, 'batch_size': 16},\n",
    "            'efficientnet_b7': {'learning_rate': 5e-5, 'dropout_rate': 0.5, 'weight_decay': 1e-4, 'batch_size': 8},\n",
    "            'xception': {'learning_rate': 1e-4, 'dropout_rate': 0.3, 'weight_decay': 1e-4, 'batch_size': 16}\n",
    "        }\n",
    "        \n",
    "        for model_name in model_names:\n",
    "            try:\n",
    "                self.optimize_and_train_model(\n",
    "                    model_name, \n",
    "                    optimize_hyperparams=optimize_hyperparams,\n",
    "                    default_params=default_params.get(model_name),\n",
    "                    epochs=epochs\n",
    "                )\n",
    "                \n",
    "                # Clear GPU memory between models\n",
    "                torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error training {model_name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"\\nTraining completed for {len(self.trained_models)} models.\")\n",
    "        return self.trained_models, self.training_histories\n",
    "    \n",
    "    def evaluate_model(self, model, data_loader, model_name):\n",
    "        \"\"\"Evaluate a trained model\"\"\"\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        all_probs = []\n",
    "        \n",
    "        print(f\"Evaluating {model_name}...\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in tqdm(data_loader, desc='Evaluating'):\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = model(data)\n",
    "                \n",
    "                # Get probabilities and predictions\n",
    "                probs = F.softmax(output, dim=1)\n",
    "                _, preds = torch.max(output, 1)\n",
    "                \n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_targets.extend(target.cpu().numpy())\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "        \n",
    "        return np.array(all_targets), np.array(all_preds), np.array(all_probs)\n",
    "\n",
    "# Initialize PyTorch trainer\n",
    "trainer = PyTorchModelTrainer(\n",
    "    model_builder, train_loader, val_loader, test_loader, \n",
    "    class_weights, device\n",
    ")\n",
    "\n",
    "print(\"PyTorch model trainer initialized.\")\n",
    "print(\"Ready to train base models with or without hyperparameter optimization.\")\n",
    "print(f\"Training will be performed on: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4bf4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation and Metrics (PyTorch)\n",
    "class PyTorchModelEvaluator:\n",
    "    def __init__(self, label_encoder, device):\n",
    "        self.label_encoder = label_encoder\n",
    "        self.class_names = label_encoder.classes_\n",
    "        self.device = device\n",
    "    \n",
    "    def evaluate_model(self, model, test_loader, model_name):\n",
    "        \"\"\"Comprehensive model evaluation\"\"\"\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"EVALUATING {model_name.upper()}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        all_probs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in tqdm(test_loader, desc='Evaluating'):\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = model(data)\n",
    "                \n",
    "                # Get probabilities and predictions\n",
    "                probs = F.softmax(output, dim=1)\n",
    "                _, preds = torch.max(output, 1)\n",
    "                \n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_targets.extend(target.cpu().numpy())\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "        \n",
    "        y_true = np.array(all_targets)\n",
    "        y_pred = np.array(all_preds)\n",
    "        y_pred_proba = np.array(all_probs)\n",
    "        \n",
    "        # Basic metrics\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        # Classification report\n",
    "        report = classification_report(\n",
    "            y_true, y_pred, \n",
    "            target_names=self.class_names,\n",
    "            output_dict=True\n",
    "        )\n",
    "        \n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_true, y_pred, target_names=self.class_names))\n",
    "        \n",
    "        # ROC AUC for multi-class\n",
    "        try:\n",
    "            auc_scores = []\n",
    "            for i in range(len(self.class_names)):\n",
    "                y_true_binary = (y_true == i).astype(int)\n",
    "                auc = roc_auc_score(y_true_binary, y_pred_proba[:, i])\n",
    "                auc_scores.append(auc)\n",
    "                print(f\"AUC for {self.class_names[i]}: {auc:.4f}\")\n",
    "            \n",
    "            macro_auc = np.mean(auc_scores)\n",
    "            print(f\"Macro-averaged AUC: {macro_auc:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not compute AUC: {e}\")\n",
    "            auc_scores = []\n",
    "            macro_auc = 0\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        # Store results\n",
    "        results = {\n",
    "            'model_name': model_name,\n",
    "            'accuracy': accuracy,\n",
    "            'classification_report': report,\n",
    "            'confusion_matrix': cm,\n",
    "            'auc_scores': auc_scores,\n",
    "            'macro_auc': macro_auc,\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "            'y_pred_proba': y_pred_proba\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def plot_training_history(self, history, model_name):\n",
    "        \"\"\"Plot training history\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle(f'{model_name.upper()} Training History', fontsize=16)\n",
    "        \n",
    "        epochs = range(1, len(history['train_loss']) + 1)\n",
    "        \n",
    "        # Loss\n",
    "        axes[0, 0].plot(epochs, history['train_loss'], label='Training')\n",
    "        axes[0, 0].plot(epochs, history['val_loss'], label='Validation')\n",
    "        axes[0, 0].set_title('Model Loss')\n",
    "        axes[0, 0].set_xlabel('Epoch')\n",
    "        axes[0, 0].set_ylabel('Loss')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True)\n",
    "        \n",
    "        # Accuracy\n",
    "        axes[0, 1].plot(epochs, history['train_acc'], label='Training')\n",
    "        axes[0, 1].plot(epochs, history['val_acc'], label='Validation')\n",
    "        axes[0, 1].set_title('Model Accuracy')\n",
    "        axes[0, 1].set_xlabel('Epoch')\n",
    "        axes[0, 1].set_ylabel('Accuracy')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True)\n",
    "        \n",
    "        # Learning rate (if available)\n",
    "        axes[1, 0].text(0.5, 0.5, 'Learning Rate\\nScheduling Applied', \n",
    "                        ha='center', va='center', transform=axes[1, 0].transAxes,\n",
    "                        fontsize=12)\n",
    "        axes[1, 0].set_title('Learning Rate Schedule')\n",
    "        \n",
    "        # Best metrics summary\n",
    "        best_train_acc = max(history['train_acc'])\n",
    "        best_val_acc = max(history['val_acc'])\n",
    "        final_train_loss = history['train_loss'][-1]\n",
    "        final_val_loss = history['val_loss'][-1]\n",
    "        \n",
    "        metrics_text = f\"Best Train Acc: {best_train_acc:.4f}\\n\"\n",
    "        metrics_text += f\"Best Val Acc: {best_val_acc:.4f}\\n\"\n",
    "        metrics_text += f\"Final Train Loss: {final_train_loss:.4f}\\n\"\n",
    "        metrics_text += f\"Final Val Loss: {final_val_loss:.4f}\"\n",
    "        \n",
    "        axes[1, 1].text(0.1, 0.5, metrics_text, transform=axes[1, 1].transAxes,\n",
    "                        fontsize=11, verticalalignment='center')\n",
    "        axes[1, 1].set_title('Training Summary')\n",
    "        axes[1, 1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_confusion_matrix(self, cm, model_name):\n",
    "        \"\"\"Plot confusion matrix\"\"\"\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=self.class_names,\n",
    "                   yticklabels=self.class_names)\n",
    "        plt.title(f'{model_name.upper()} - Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_roc_curves(self, results_dict):\n",
    "        \"\"\"Plot ROC curves for all models\"\"\"\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        for i, class_name in enumerate(self.class_names):\n",
    "            plt.subplot(1, 3, i+1)\n",
    "            \n",
    "            for model_name, results in results_dict.items():\n",
    "                if len(results['auc_scores']) > i:\n",
    "                    y_true_binary = (results['y_true'] == i).astype(int)\n",
    "                    y_pred_proba_binary = results['y_pred_proba'][:, i]\n",
    "                    \n",
    "                    fpr, tpr, _ = roc_curve(y_true_binary, y_pred_proba_binary)\n",
    "                    auc = results['auc_scores'][i]\n",
    "                    \n",
    "                    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc:.3f})')\n",
    "            \n",
    "            plt.plot([0, 1], [0, 1], 'k--', alpha=0.6)\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title(f'ROC Curve - {class_name}')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def compare_models(self, results_dict):\n",
    "        \"\"\"Compare all models performance\"\"\"\n",
    "        comparison_data = []\n",
    "        \n",
    "        for model_name, results in results_dict.items():\n",
    "            comparison_data.append({\n",
    "                'Model': model_name.capitalize(),\n",
    "                'Accuracy': results['accuracy'],\n",
    "                'Macro AUC': results['macro_auc'],\n",
    "                'Precision (Macro)': results['classification_report']['macro avg']['precision'],\n",
    "                'Recall (Macro)': results['classification_report']['macro avg']['recall'],\n",
    "                'F1-Score (Macro)': results['classification_report']['macro avg']['f1-score']\n",
    "            })\n",
    "        \n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"MODEL COMPARISON SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        print(comparison_df.to_string(index=False, float_format='%.4f'))\n",
    "        \n",
    "        # Plot comparison\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Accuracy comparison\n",
    "        axes[0].bar(comparison_df['Model'], comparison_df['Accuracy'], \n",
    "                   color=['skyblue', 'lightcoral', 'lightgreen', 'orange'])\n",
    "        axes[0].set_title('Model Accuracy Comparison')\n",
    "        axes[0].set_ylabel('Accuracy')\n",
    "        axes[0].set_ylim(0, 1)\n",
    "        for i, v in enumerate(comparison_df['Accuracy']):\n",
    "            axes[0].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Multi-metric comparison\n",
    "        metrics = ['Accuracy', 'Macro AUC', 'Precision (Macro)', 'Recall (Macro)', 'F1-Score (Macro)']\n",
    "        x = np.arange(len(comparison_df))\n",
    "        width = 0.15\n",
    "        \n",
    "        for i, metric in enumerate(metrics):\n",
    "            axes[1].bar(x + i*width, comparison_df[metric], width, \n",
    "                       label=metric, alpha=0.8)\n",
    "        \n",
    "        axes[1].set_title('Multi-Metric Comparison')\n",
    "        axes[1].set_ylabel('Score')\n",
    "        axes[1].set_xlabel('Models')\n",
    "        axes[1].set_xticks(x + width * 2)\n",
    "        axes[1].set_xticklabels(comparison_df['Model'])\n",
    "        axes[1].legend()\n",
    "        axes[1].set_ylim(0, 1)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return comparison_df\n",
    "\n",
    "# Initialize PyTorch evaluator\n",
    "evaluator = PyTorchModelEvaluator(train_dataset.label_encoder, device)\n",
    "\n",
    "print(\"PyTorch model evaluator initialized.\")\n",
    "print(\"Ready to evaluate trained models and generate comprehensive metrics.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b764fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Ensemble Learning Model (PyTorch)\n",
    "class PyTorchSequentialEnsemble:\n",
    "    def __init__(self, base_models, model_names, label_encoder, device):\n",
    "        self.base_models = base_models\n",
    "        self.model_names = model_names\n",
    "        self.label_encoder = label_encoder\n",
    "        self.device = device\n",
    "        self.ensemble_weights = None\n",
    "        self.meta_model = None\n",
    "        self.num_classes = len(label_encoder.classes_)\n",
    "    \n",
    "    def extract_features(self, data_loader, verbose=True):\n",
    "        \"\"\"Extract features from all base models\"\"\"\n",
    "        if verbose:\n",
    "            print(\"Extracting features from base models...\")\n",
    "        \n",
    "        base_predictions = {}\n",
    "        \n",
    "        for name, model in zip(self.model_names, self.base_models):\n",
    "            if verbose:\n",
    "                print(f\"Extracting features from {name}...\")\n",
    "            \n",
    "            model.eval()\n",
    "            predictions = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for data, _ in tqdm(data_loader, desc=f'Extracting {name}', disable=not verbose):\n",
    "                    data = data.to(self.device)\n",
    "                    output = model(data)\n",
    "                    probs = F.softmax(output, dim=1)\n",
    "                    predictions.append(probs.cpu().numpy())\n",
    "            \n",
    "            base_predictions[name] = np.vstack(predictions)\n",
    "        \n",
    "        return base_predictions\n",
    "    \n",
    "    def simple_voting_ensemble(self, test_loader, voting_type='soft'):\n",
    "        \"\"\"Simple voting ensemble (soft or hard voting)\"\"\"\n",
    "        print(f\"\\nPerforming {voting_type} voting ensemble...\")\n",
    "        \n",
    "        base_predictions = self.extract_features(test_loader)\n",
    "        \n",
    "        if voting_type == 'soft':\n",
    "            # Average probabilities\n",
    "            ensemble_pred_proba = np.mean(\n",
    "                [pred for pred in base_predictions.values()], axis=0\n",
    "            )\n",
    "            ensemble_pred = np.argmax(ensemble_pred_proba, axis=1)\n",
    "        else:\n",
    "            # Hard voting - majority vote\n",
    "            hard_predictions = []\n",
    "            for pred in base_predictions.values():\n",
    "                hard_predictions.append(np.argmax(pred, axis=1))\n",
    "            \n",
    "            ensemble_pred = []\n",
    "            for i in range(len(hard_predictions[0])):\n",
    "                votes = [pred[i] for pred in hard_predictions]\n",
    "                ensemble_pred.append(max(set(votes), key=votes.count))\n",
    "            \n",
    "            ensemble_pred = np.array(ensemble_pred)\n",
    "            ensemble_pred_proba = None\n",
    "        \n",
    "        return ensemble_pred, ensemble_pred_proba\n",
    "    \n",
    "    def weighted_ensemble(self, val_loader, test_loader, method='accuracy'):\n",
    "        \"\"\"Weighted ensemble based on individual model performance\"\"\"\n",
    "        print(f\"\\nCreating weighted ensemble based on {method}...\")\n",
    "        \n",
    "        # Get validation predictions for weight calculation\n",
    "        val_predictions = self.extract_features(val_loader)\n",
    "        \n",
    "        # Get true labels\n",
    "        y_val_true = []\n",
    "        for _, target in val_loader:\n",
    "            y_val_true.extend(target.numpy())\n",
    "        y_val_true = np.array(y_val_true)\n",
    "        \n",
    "        # Calculate weights based on performance\n",
    "        weights = []\n",
    "        for name, pred in val_predictions.items():\n",
    "            y_pred = np.argmax(pred, axis=1)[:len(y_val_true)]\n",
    "            \n",
    "            if method == 'accuracy':\n",
    "                weight = accuracy_score(y_val_true, y_pred)\n",
    "            elif method == 'auc':\n",
    "                try:\n",
    "                    auc_scores = []\n",
    "                    for i in range(self.num_classes):\n",
    "                        y_true_binary = (y_val_true == i).astype(int)\n",
    "                        auc = roc_auc_score(y_true_binary, pred[:len(y_val_true), i])\n",
    "                        auc_scores.append(auc)\n",
    "                    weight = np.mean(auc_scores)\n",
    "                except:\n",
    "                    weight = 0.5  # Fallback weight\n",
    "            \n",
    "            weights.append(weight)\n",
    "            print(f\"{name} weight ({method}): {weight:.4f}\")\n",
    "        \n",
    "        # Normalize weights\n",
    "        weights = np.array(weights)\n",
    "        weights = weights / np.sum(weights)\n",
    "        \n",
    "        print(f\"Normalized weights: {dict(zip(self.model_names, weights))}\")\n",
    "        self.ensemble_weights = weights\n",
    "        \n",
    "        # Get test predictions\n",
    "        test_predictions = self.extract_features(test_loader)\n",
    "        \n",
    "        # Weighted average\n",
    "        weighted_pred_proba = np.zeros_like(list(test_predictions.values())[0])\n",
    "        for i, (name, pred) in enumerate(test_predictions.items()):\n",
    "            weighted_pred_proba += weights[i] * pred\n",
    "        \n",
    "        ensemble_pred = np.argmax(weighted_pred_proba, axis=1)\n",
    "        \n",
    "        return ensemble_pred, weighted_pred_proba\n",
    "    \n",
    "    def meta_learner_ensemble(self, train_loader, val_loader, test_loader):\n",
    "        \"\"\"Meta-learner ensemble using a neural network\"\"\"\n",
    "        print(\"\\nTraining meta-learner ensemble...\")\n",
    "        \n",
    "        # Extract features from training set\n",
    "        print(\"Extracting training features...\")\n",
    "        train_predictions = self.extract_features(train_loader, verbose=False)\n",
    "        \n",
    "        # Prepare meta-training data\n",
    "        X_meta_train = np.hstack([pred for pred in train_predictions.values()])\n",
    "        \n",
    "        # Get true labels for training\n",
    "        y_meta_train = []\n",
    "        for _, target in train_loader:\n",
    "            y_meta_train.extend(target.numpy())\n",
    "        y_meta_train = np.array(y_meta_train[:len(X_meta_train)])\n",
    "        \n",
    "        # Extract features from validation set\n",
    "        print(\"Extracting validation features...\")\n",
    "        val_predictions = self.extract_features(val_loader, verbose=False)\n",
    "        X_meta_val = np.hstack([pred for pred in val_predictions.values()])\n",
    "        \n",
    "        # Get true labels for validation\n",
    "        y_meta_val = []\n",
    "        for _, target in val_loader:\n",
    "            y_meta_val.extend(target.numpy())\n",
    "        y_meta_val = np.array(y_meta_val[:len(X_meta_val)])\n",
    "        \n",
    "        # Build meta-model\n",
    "        meta_input_dim = X_meta_train.shape[1]\n",
    "        \n",
    "        class MetaLearner(nn.Module):\n",
    "            def __init__(self, input_dim, num_classes):\n",
    "                super(MetaLearner, self).__init__()\n",
    "                self.layers = nn.Sequential(\n",
    "                    nn.Linear(input_dim, 128),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(128, 64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(64, num_classes)\n",
    "                )\n",
    "            \n",
    "            def forward(self, x):\n",
    "                return self.layers(x)\n",
    "        \n",
    "        self.meta_model = MetaLearner(meta_input_dim, self.num_classes).to(self.device)\n",
    "        \n",
    "        # Prepare data for PyTorch\n",
    "        X_train_tensor = torch.FloatTensor(X_meta_train).to(self.device)\n",
    "        y_train_tensor = torch.LongTensor(y_meta_train).to(self.device)\n",
    "        X_val_tensor = torch.FloatTensor(X_meta_val).to(self.device)\n",
    "        y_val_tensor = torch.LongTensor(y_meta_val).to(self.device)\n",
    "        \n",
    "        # Create data loaders for meta-training\n",
    "        meta_train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        meta_val_dataset = torch.utils.data.TensorDataset(X_val_tensor, y_val_tensor)\n",
    "        \n",
    "        meta_train_loader = DataLoader(meta_train_dataset, batch_size=32, shuffle=True)\n",
    "        meta_val_loader = DataLoader(meta_val_dataset, batch_size=32, shuffle=False)\n",
    "        \n",
    "        # Train meta-model\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.meta_model.parameters(), lr=0.001)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "        \n",
    "        print(\"Training meta-model...\")\n",
    "        meta_history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "        \n",
    "        best_val_acc = 0.0\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(50):\n",
    "            # Training\n",
    "            self.meta_model.train()\n",
    "            train_loss = 0\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            \n",
    "            for X_batch, y_batch in meta_train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.meta_model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                train_total += y_batch.size(0)\n",
    "                train_correct += (predicted == y_batch).sum().item()\n",
    "            \n",
    "            # Validation\n",
    "            self.meta_model.eval()\n",
    "            val_loss = 0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for X_batch, y_batch in meta_val_loader:\n",
    "                    outputs = self.meta_model(X_batch)\n",
    "                    loss = criterion(outputs, y_batch)\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    val_total += y_batch.size(0)\n",
    "                    val_correct += (predicted == y_batch).sum().item()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            train_acc = train_correct / train_total\n",
    "            val_acc = val_correct / val_total\n",
    "            \n",
    "            meta_history['train_loss'].append(train_loss / len(meta_train_loader))\n",
    "            meta_history['train_acc'].append(train_acc)\n",
    "            meta_history['val_loss'].append(val_loss / len(meta_val_loader))\n",
    "            meta_history['val_acc'].append(val_acc)\n",
    "            \n",
    "            scheduler.step(val_acc)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch {epoch}: Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "            \n",
    "            # Early stopping\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                \n",
    "            if patience_counter >= 10:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "        \n",
    "        # Get test predictions\n",
    "        print(\"Generating ensemble predictions...\")\n",
    "        test_predictions = self.extract_features(test_loader, verbose=False)\n",
    "        X_meta_test = np.hstack([pred for pred in test_predictions.values()])\n",
    "        X_test_tensor = torch.FloatTensor(X_meta_test).to(self.device)\n",
    "        \n",
    "        # Meta-model predictions\n",
    "        self.meta_model.eval()\n",
    "        with torch.no_grad():\n",
    "            ensemble_output = self.meta_model(X_test_tensor)\n",
    "            ensemble_pred_proba = F.softmax(ensemble_output, dim=1).cpu().numpy()\n",
    "        \n",
    "        ensemble_pred = np.argmax(ensemble_pred_proba, axis=1)\n",
    "        \n",
    "        return ensemble_pred, ensemble_pred_proba, meta_history\n",
    "    \n",
    "    def evaluate_ensemble(self, y_true, y_pred, y_pred_proba, ensemble_name):\n",
    "        \"\"\"Evaluate ensemble performance\"\"\"\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"ENSEMBLE EVALUATION: {ensemble_name.upper()}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Basic metrics\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        print(f\"Ensemble Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        # Classification report\n",
    "        report = classification_report(\n",
    "            y_true, y_pred,\n",
    "            target_names=self.label_encoder.classes_,\n",
    "            output_dict=True\n",
    "        )\n",
    "        \n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_true, y_pred, target_names=self.label_encoder.classes_))\n",
    "        \n",
    "        # AUC scores\n",
    "        if y_pred_proba is not None:\n",
    "            try:\n",
    "                auc_scores = []\n",
    "                for i in range(self.num_classes):\n",
    "                    y_true_binary = (y_true == i).astype(int)\n",
    "                    auc = roc_auc_score(y_true_binary, y_pred_proba[:, i])\n",
    "                    auc_scores.append(auc)\n",
    "                    print(f\"AUC for {self.label_encoder.classes_[i]}: {auc:.4f}\")\n",
    "                \n",
    "                macro_auc = np.mean(auc_scores)\n",
    "                print(f\"Macro-averaged AUC: {macro_auc:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not compute AUC: {e}\")\n",
    "                auc_scores = []\n",
    "                macro_auc = 0\n",
    "        else:\n",
    "            auc_scores = []\n",
    "            macro_auc = 0\n",
    "        \n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        results = {\n",
    "            'ensemble_name': ensemble_name,\n",
    "            'accuracy': accuracy,\n",
    "            'classification_report': report,\n",
    "            'confusion_matrix': cm,\n",
    "            'auc_scores': auc_scores,\n",
    "            'macro_auc': macro_auc,\n",
    "            'y_pred': y_pred,\n",
    "            'y_pred_proba': y_pred_proba\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "\n",
    "print(\"PyTorch Sequential Ensemble Learning class defined.\")\n",
    "print(\"Ready to create ensemble models from trained base models.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d05187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Complete Pipeline (PyTorch)\n",
    "\n",
    "# Configuration\n",
    "QUICK_MODE = True  # Set to False for full optimization with genetic algorithm\n",
    "EPOCHS = 10 if QUICK_MODE else 40\n",
    "OPTIMIZE_HYPERPARAMS = False if QUICK_MODE else True\n",
    "\n",
    "print(f\"Running in {'QUICK' if QUICK_MODE else 'FULL'} mode\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Hyperparameter optimization: {OPTIMIZE_HYPERPARAMS}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING COMPLETE ENSEMBLE LEARNING PIPELINE (PyTorch)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Step 1: Train all base models\n",
    "print(\"\\nSTEP 1: Training Base Models\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "trained_models, training_histories = trainer.train_all_models(\n",
    "    optimize_hyperparams=OPTIMIZE_HYPERPARAMS, \n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "print(f\"\\nTrained {len(trained_models)} base models successfully.\")\n",
    "\n",
    "# Step 2: Evaluate individual base models\n",
    "print(\"\\nSTEP 2: Evaluating Base Models\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "base_model_results = {}\n",
    "for model_name, model in trained_models.items():\n",
    "    try:\n",
    "        # Get test predictions\n",
    "        y_true, y_pred, y_pred_proba = trainer.evaluate_model(model, test_loader, model_name)\n",
    "        \n",
    "        # Create results dictionary in the same format as evaluator expects\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        report = classification_report(y_true, y_pred, target_names=evaluator.class_names, output_dict=True)\n",
    "        \n",
    "        # Calculate AUC scores\n",
    "        auc_scores = []\n",
    "        try:\n",
    "            for i in range(len(evaluator.class_names)):\n",
    "                y_true_binary = (y_true == i).astype(int)\n",
    "                auc = roc_auc_score(y_true_binary, y_pred_proba[:, i])\n",
    "                auc_scores.append(auc)\n",
    "            macro_auc = np.mean(auc_scores)\n",
    "        except:\n",
    "            auc_scores = []\n",
    "            macro_auc = 0\n",
    "        \n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        results = {\n",
    "            'model_name': model_name,\n",
    "            'accuracy': accuracy,\n",
    "            'classification_report': report,\n",
    "            'confusion_matrix': cm,\n",
    "            'auc_scores': auc_scores,\n",
    "            'macro_auc': macro_auc,\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "            'y_pred_proba': y_pred_proba\n",
    "        }\n",
    "        \n",
    "        base_model_results[model_name] = results\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\n{model_name.upper()} Results:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Macro AUC: {macro_auc:.4f}\")\n",
    "        \n",
    "        # Plot training history\n",
    "        evaluator.plot_training_history(training_histories[model_name], model_name)\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        evaluator.plot_confusion_matrix(results['confusion_matrix'], model_name)\n",
    "        \n",
    "        # Clear GPU memory\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating {model_name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Compare base models\n",
    "if base_model_results:\n",
    "    print(\"\\nSTEP 2.1: Base Model Comparison\")\n",
    "    comparison_df = evaluator.compare_models(base_model_results)\n",
    "    \n",
    "    # Plot ROC curves\n",
    "    evaluator.plot_roc_curves(base_model_results)\n",
    "\n",
    "print(f\"\\nBase model evaluation completed for {len(base_model_results)} models.\")\n",
    "\n",
    "# Memory management\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU memory used: {torch.cuda.memory_allocated(device) / 1024**3:.2f} GB\")\n",
    "    print(f\"GPU memory cached: {torch.cuda.memory_reserved(device) / 1024**3:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bd407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create and Evaluate Ensemble Models (PyTorch)\n",
    "print(\"\\nSTEP 3: Creating Ensemble Models\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if len(trained_models) >= 2:  # Need at least 2 models for ensemble\n",
    "    # Initialize ensemble\n",
    "    model_list = list(trained_models.values())\n",
    "    model_names = list(trained_models.keys())\n",
    "    \n",
    "    ensemble = PyTorchSequentialEnsemble(\n",
    "        base_models=model_list,\n",
    "        model_names=model_names,\n",
    "        label_encoder=train_dataset.label_encoder,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Get true test labels for evaluation\n",
    "    y_test_true = []\n",
    "    for _, target in test_loader:\n",
    "        y_test_true.extend(target.numpy())\n",
    "    y_test_true = np.array(y_test_true)\n",
    "    \n",
    "    ensemble_results = {}\n",
    "    \n",
    "    # 3.1: Simple Soft Voting Ensemble\n",
    "    print(\"\\n3.1: Soft Voting Ensemble\")\n",
    "    try:\n",
    "        soft_pred, soft_pred_proba = ensemble.simple_voting_ensemble(\n",
    "            test_loader, voting_type='soft'\n",
    "        )\n",
    "        \n",
    "        # Ensure same length\n",
    "        min_len = min(len(y_test_true), len(soft_pred))\n",
    "        y_test_true_trimmed = y_test_true[:min_len]\n",
    "        soft_pred_trimmed = soft_pred[:min_len]\n",
    "        soft_pred_proba_trimmed = soft_pred_proba[:min_len] if soft_pred_proba is not None else None\n",
    "        \n",
    "        soft_results = ensemble.evaluate_ensemble(\n",
    "            y_test_true_trimmed, soft_pred_trimmed, soft_pred_proba_trimmed, \"Soft Voting\"\n",
    "        )\n",
    "        ensemble_results['soft_voting'] = soft_results\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        evaluator.plot_confusion_matrix(soft_results['confusion_matrix'], \"Soft Voting Ensemble\")\n",
    "        \n",
    "        # Clear memory\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with soft voting ensemble: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # 3.2: Hard Voting Ensemble\n",
    "    print(\"\\n3.2: Hard Voting Ensemble\")\n",
    "    try:\n",
    "        hard_pred, hard_pred_proba = ensemble.simple_voting_ensemble(\n",
    "            test_loader, voting_type='hard'\n",
    "        )\n",
    "        \n",
    "        # Ensure same length\n",
    "        min_len = min(len(y_test_true), len(hard_pred))\n",
    "        y_test_true_trimmed = y_test_true[:min_len]\n",
    "        hard_pred_trimmed = hard_pred[:min_len]\n",
    "        \n",
    "        hard_results = ensemble.evaluate_ensemble(\n",
    "            y_test_true_trimmed, hard_pred_trimmed, None, \"Hard Voting\"\n",
    "        )\n",
    "        ensemble_results['hard_voting'] = hard_results\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        evaluator.plot_confusion_matrix(hard_results['confusion_matrix'], \"Hard Voting Ensemble\")\n",
    "        \n",
    "        # Clear memory\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with hard voting ensemble: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # 3.3: Weighted Ensemble (based on accuracy)\n",
    "    print(\"\\n3.3: Weighted Ensemble\")\n",
    "    try:\n",
    "        weighted_pred, weighted_pred_proba = ensemble.weighted_ensemble(\n",
    "            val_loader, test_loader, method='accuracy'\n",
    "        )\n",
    "        \n",
    "        # Ensure same length\n",
    "        min_len = min(len(y_test_true), len(weighted_pred))\n",
    "        y_test_true_trimmed = y_test_true[:min_len]\n",
    "        weighted_pred_trimmed = weighted_pred[:min_len]\n",
    "        weighted_pred_proba_trimmed = weighted_pred_proba[:min_len] if weighted_pred_proba is not None else None\n",
    "        \n",
    "        weighted_results = ensemble.evaluate_ensemble(\n",
    "            y_test_true_trimmed, weighted_pred_trimmed, weighted_pred_proba_trimmed, \"Weighted Ensemble\"\n",
    "        )\n",
    "        ensemble_results['weighted'] = weighted_results\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        evaluator.plot_confusion_matrix(weighted_results['confusion_matrix'], \"Weighted Ensemble\")\n",
    "        \n",
    "        # Clear memory\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with weighted ensemble: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # 3.4: Meta-learner Ensemble (if not in quick mode)\n",
    "    if not QUICK_MODE:\n",
    "        print(\"\\n3.4: Meta-learner Ensemble\")\n",
    "        try:\n",
    "            meta_pred, meta_pred_proba, meta_history = ensemble.meta_learner_ensemble(\n",
    "                train_loader, val_loader, test_loader\n",
    "            )\n",
    "            \n",
    "            # Ensure same length\n",
    "            min_len = min(len(y_test_true), len(meta_pred))\n",
    "            y_test_true_trimmed = y_test_true[:min_len]\n",
    "            meta_pred_trimmed = meta_pred[:min_len]\n",
    "            meta_pred_proba_trimmed = meta_pred_proba[:min_len] if meta_pred_proba is not None else None\n",
    "            \n",
    "            meta_results = ensemble.evaluate_ensemble(\n",
    "                y_test_true_trimmed, meta_pred_trimmed, meta_pred_proba_trimmed, \"Meta-learner Ensemble\"\n",
    "            )\n",
    "            ensemble_results['meta_learner'] = meta_results\n",
    "            \n",
    "            # Plot confusion matrix\n",
    "            evaluator.plot_confusion_matrix(meta_results['confusion_matrix'], \"Meta-learner Ensemble\")\n",
    "            \n",
    "            # Plot meta-model training history\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            \n",
    "            epochs = range(1, len(meta_history['train_acc']) + 1)\n",
    "            \n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(epochs, meta_history['train_acc'], label='Training')\n",
    "            plt.plot(epochs, meta_history['val_acc'], label='Validation')\n",
    "            plt.title('Meta-model Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(epochs, meta_history['train_loss'], label='Training')\n",
    "            plt.plot(epochs, meta_history['val_loss'], label='Validation')\n",
    "            plt.title('Meta-model Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Clear memory\n",
    "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error with meta-learner ensemble: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        print(\"\\n3.4: Meta-learner Ensemble (Skipped in QUICK_MODE)\")\n",
    "    \n",
    "    print(f\"\\nEnsemble evaluation completed for {len(ensemble_results)} ensemble methods.\")\n",
    "    \n",
    "    # Final memory cleanup\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"\\nFinal GPU memory used: {torch.cuda.memory_allocated(device) / 1024**3:.2f} GB\")\n",
    "        print(f\"Final GPU memory cached: {torch.cuda.memory_reserved(device) / 1024**3:.2f} GB\")\n",
    "    \n",
    "else:\n",
    "    print(\"Not enough trained models for ensemble learning.\")\n",
    "    ensemble_results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a813ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Final Results Summary and Comparison (PyTorch)\n",
    "print(\"\\nSTEP 4: Final Results Summary\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Combine all results for comprehensive comparison\n",
    "all_results = {}\n",
    "\n",
    "# Add base model results\n",
    "for model_name, results in base_model_results.items():\n",
    "    all_results[f\"Base: {model_name.capitalize()}\"] = {\n",
    "        'accuracy': results['accuracy'],\n",
    "        'macro_auc': results['macro_auc'],\n",
    "        'precision': results['classification_report']['macro avg']['precision'],\n",
    "        'recall': results['classification_report']['macro avg']['recall'],\n",
    "        'f1_score': results['classification_report']['macro avg']['f1-score']\n",
    "    }\n",
    "\n",
    "# Add ensemble results\n",
    "for ensemble_name, results in ensemble_results.items():\n",
    "    all_results[f\"Ensemble: {ensemble_name.replace('_', ' ').title()}\"] = {\n",
    "        'accuracy': results['accuracy'],\n",
    "        'macro_auc': results['macro_auc'],\n",
    "        'precision': results['classification_report']['macro avg']['precision'],\n",
    "        'recall': results['classification_report']['macro avg']['recall'],\n",
    "        'f1_score': results['classification_report']['macro avg']['f1-score']\n",
    "    }\n",
    "\n",
    "# Create comprehensive comparison\n",
    "if all_results:\n",
    "    final_comparison = pd.DataFrame.from_dict(all_results, orient='index')\n",
    "    final_comparison = final_comparison.round(4)\n",
    "    \n",
    "    print(\"\\nCOMPREHENSIVE MODEL COMPARISON (PyTorch)\")\n",
    "    print(\"-\" * 80)\n",
    "    print(final_comparison.to_string(float_format='%.4f'))\n",
    "    \n",
    "    # Find best performing models\n",
    "    best_accuracy = final_comparison['accuracy'].max()\n",
    "    best_auc = final_comparison['macro_auc'].max()\n",
    "    best_f1 = final_comparison['f1_score'].max()\n",
    "    \n",
    "    best_accuracy_model = final_comparison[final_comparison['accuracy'] == best_accuracy].index[0]\n",
    "    best_auc_model = final_comparison[final_comparison['macro_auc'] == best_auc].index[0]\n",
    "    best_f1_model = final_comparison[final_comparison['f1_score'] == best_f1].index[0]\n",
    "    \n",
    "    print(f\"\\nBEST PERFORMING MODELS:\")\n",
    "    print(f\"Highest Accuracy: {best_accuracy_model} ({best_accuracy:.4f})\")\n",
    "    print(f\"Highest AUC: {best_auc_model} ({best_auc:.4f})\")\n",
    "    print(f\"Highest F1-Score: {best_f1_model} ({best_f1:.4f})\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Accuracy comparison\n",
    "    axes[0, 0].barh(range(len(final_comparison)), final_comparison['accuracy'], \n",
    "                    color=['lightblue' if 'Base:' in idx else 'lightcoral' for idx in final_comparison.index])\n",
    "    axes[0, 0].set_yticks(range(len(final_comparison)))\n",
    "    axes[0, 0].set_yticklabels(final_comparison.index, fontsize=8)\n",
    "    axes[0, 0].set_xlabel('Accuracy')\n",
    "    axes[0, 0].set_title('Model Accuracy Comparison (PyTorch)')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # AUC comparison\n",
    "    axes[0, 1].barh(range(len(final_comparison)), final_comparison['macro_auc'], \n",
    "                    color=['lightblue' if 'Base:' in idx else 'lightcoral' for idx in final_comparison.index])\n",
    "    axes[0, 1].set_yticks(range(len(final_comparison)))\n",
    "    axes[0, 1].set_yticklabels(final_comparison.index, fontsize=8)\n",
    "    axes[0, 1].set_xlabel('Macro AUC')\n",
    "    axes[0, 1].set_title('Model AUC Comparison (PyTorch)')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # F1-Score comparison\n",
    "    axes[1, 0].barh(range(len(final_comparison)), final_comparison['f1_score'], \n",
    "                    color=['lightblue' if 'Base:' in idx else 'lightcoral' for idx in final_comparison.index])\n",
    "    axes[1, 0].set_yticks(range(len(final_comparison)))\n",
    "    axes[1, 0].set_yticklabels(final_comparison.index, fontsize=8)\n",
    "    axes[1, 0].set_xlabel('F1-Score')\n",
    "    axes[1, 0].set_title('Model F1-Score Comparison (PyTorch)')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Multi-metric radar chart for top 3 models\n",
    "    top_3_models = final_comparison.nlargest(3, 'accuracy')\n",
    "    \n",
    "    metrics = ['accuracy', 'macro_auc', 'precision', 'recall', 'f1_score']\n",
    "    angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()\n",
    "    angles += angles[:1]  # Complete the circle\n",
    "    \n",
    "    ax = plt.subplot(2, 2, 4, projection='polar')\n",
    "    \n",
    "    colors = ['red', 'blue', 'green']\n",
    "    for i, (model_name, row) in enumerate(top_3_models.iterrows()):\n",
    "        values = [row[metric] for metric in metrics]\n",
    "        values += values[:1]  # Complete the circle\n",
    "        \n",
    "        ax.plot(angles, values, 'o-', linewidth=2, label=model_name[:20], color=colors[i])\n",
    "        ax.fill(angles, values, alpha=0.25, color=colors[i])\n",
    "    \n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels([m.replace('_', ' ').title() for m in metrics])\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title('Top 3 Models - Multi-Metric Comparison')\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "    ax.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Print hyperparameters used (if optimization was performed)\n",
    "if trainer.best_params:\n",
    "    print(\"\\nOPTIMIZED HYPERPARAMETERS (PyTorch):\")\n",
    "    print(\"-\" * 40)\n",
    "    for model_name, params in trainer.best_params.items():\n",
    "        print(f\"\\n{model_name.upper()}:\")\n",
    "        for param, value in params.items():\n",
    "            if param != 'fitness':\n",
    "                print(f\"  {param}: {value}\")\n",
    "        if 'fitness' in params:\n",
    "            print(f\"  Validation Accuracy: {params['fitness']:.4f}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nPYTORCH PIPELINE EXECUTION SUMMARY:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Framework: PyTorch {torch.__version__}\")\n",
    "print(f\"Device used: {device}\")\n",
    "print(f\"Total base models trained: {len(trained_models)}\")\n",
    "print(f\"Total ensemble methods tested: {len(ensemble_results)}\")\n",
    "print(f\"Total evaluation metrics computed: {len(all_results)}\")\n",
    "\n",
    "if all_results:\n",
    "    print(f\"Best overall accuracy: {final_comparison['accuracy'].max():.4f}\")\n",
    "    print(f\"Best overall AUC: {final_comparison['macro_auc'].max():.4f}\")\n",
    "    print(f\"Best overall F1-score: {final_comparison['f1_score'].max():.4f}\")\n",
    "\n",
    "if QUICK_MODE:\n",
    "    print(\"\\nNote: Pipeline was run in QUICK mode. For production use, consider:\")\n",
    "    print(\"- Setting QUICK_MODE = False for full optimization\")\n",
    "    print(\"- Increasing EPOCHS for better convergence\")\n",
    "    print(\"- Running genetic algorithm optimization\")\n",
    "    print(\"- Using larger population sizes and more generations\")\n",
    "    print(\"- Enabling meta-learner ensemble\")\n",
    "\n",
    "# Final memory cleanup and statistics\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"\\nFinal GPU memory statistics:\")\n",
    "    print(f\"- Memory allocated: {torch.cuda.memory_allocated(device) / 1024**3:.2f} GB\")\n",
    "    print(f\"- Memory cached: {torch.cuda.memory_reserved(device) / 1024**3:.2f} GB\")\n",
    "    print(f\"- Max memory allocated: {torch.cuda.max_memory_allocated(device) / 1024**3:.2f} GB\")\n",
    " \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PyTorch ENSEMBLE LEARNING PIPELINE COMPLETED SUCCESSFULLY!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JointWise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
