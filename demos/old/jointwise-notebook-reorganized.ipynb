{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f139cdd8",
   "metadata": {},
   "source": [
    "# ðŸ©» JointWise: Multi-Task Medical Image Analysis\n",
    "## Ensemble Learning Pipeline for Knee MRI Classification and Localization\n",
    "\n",
    "This notebook implements a comprehensive pipeline for:\n",
    "- **Data Processing**: Converting FastMRI H5 to DICOM and PNG formats\n",
    "- **Single-Task Learning**: Classification of ACL tears vs Meniscus tears\n",
    "- **Multi-Task Learning**: Combined classification and bounding box regression\n",
    "- **Ensemble Methods**: Advanced model combination techniques\n",
    "\n",
    "### Pipeline Overview:\n",
    "1. **Data Setup & Preprocessing**\n",
    "2. **Single-Task Model Training**\n",
    "3. **Multi-Task Learning Implementation**\n",
    "4. **Ensemble Learning & Evaluation**\n",
    "5. **Results Analysis & Visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c0cb67",
   "metadata": {},
   "source": [
    "# ðŸ“¦ 1. Environment Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4a1df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports for ensemble learning pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch deep learning framework\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "import timm  # For advanced model architectures\n",
    "\n",
    "# Data augmentation\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Machine learning utilities\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score, \n",
    "    precision_recall_curve, roc_curve, accuracy_score\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Genetic algorithm for hyperparameter optimization\n",
    "import deap\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Medical data processing\n",
    "import h5py\n",
    "import pydicom\n",
    "from pydicom.dataset import Dataset as DicomDataset, FileMetaDataset\n",
    "from pydicom.uid import generate_uid\n",
    "import xmltodict\n",
    "from PIL import Image\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "print(\"âœ… All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be35cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment configuration\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Set deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Environment setup complete.\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e515b3c",
   "metadata": {},
   "source": [
    "# ðŸ”„ 2. Data Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb72251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastMRI to DICOM conversion function\n",
    "def fastmri_to_dicom(filename: Path,\n",
    "    reconstruction_name: str,\n",
    "    outfolder: Path,\n",
    "    flip_up_down: bool = False,\n",
    "    flip_left_right: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Convert FastMRI H5 files to DICOM format\n",
    "    \n",
    "    Args:\n",
    "        filename: Path to H5 file\n",
    "        reconstruction_name: Name of reconstruction in H5 file\n",
    "        outfolder: Output directory for DICOM files\n",
    "        flip_up_down: Whether to flip image vertically\n",
    "        flip_left_right: Whether to flip image horizontally\n",
    "    \"\"\"\n",
    "    fileparts = os.path.splitext(filename.name)\n",
    "    patientName = fileparts[0]\n",
    "    f = h5py.File(filename,'r')\n",
    "    \n",
    "    if not outfolder:\n",
    "        outfolder = Path(patientName)\n",
    "        outfolder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if 'ismrmrd_header' not in f.keys():\n",
    "        raise Exception('ISMRMRD header not found in file')\n",
    "    if reconstruction_name not in f.keys():\n",
    "        raise Exception('Reconstruction name not found in file')\n",
    "    \n",
    "    # Parse header information\n",
    "    head = xmltodict.parse(f['ismrmrd_header'][()])\n",
    "    reconSpace = head['ismrmrdHeader']['encoding']['reconSpace']\n",
    "    measurementInformation = head['ismrmrdHeader']['measurementInformation']\n",
    "    acquisitionSystemInformation = head['ismrmrdHeader']['acquisitionSystemInformation']\n",
    "    H1resonanceFrequency_Hz = head['ismrmrdHeader']['experimentalConditions']['H1resonanceFrequency_Hz']\n",
    "    sequenceParameters = head['ismrmrdHeader']['sequenceParameters']\n",
    "    \n",
    "    # Calculate pixel spacing\n",
    "    pixelSizeX = float(reconSpace['fieldOfView_mm']['x'])/float(reconSpace['matrixSize']['x'])\n",
    "    pixelSizeY = float(reconSpace['fieldOfView_mm']['y'])/float(reconSpace['matrixSize']['y'])\n",
    "    \n",
    "    # Load and process image data\n",
    "    img_data = f[reconstruction_name][:]\n",
    "    slices = img_data.shape[0]\n",
    "    \n",
    "    if flip_left_right:\n",
    "        img_data = img_data[:, :, ::-1]\n",
    "    if flip_up_down:\n",
    "        img_data = img_data[:, ::-1, :]\n",
    "    \n",
    "    # Scale image data\n",
    "    image_max = 1024\n",
    "    scale = image_max / np.percentile(img_data, 99.9)\n",
    "    pixels_scaled = np.clip((scale * img_data), 0, image_max).astype('int16')\n",
    "    \n",
    "    # Calculate window parameters\n",
    "    windowWidth = 2 * (np.percentile(pixels_scaled, 99.9) - np.percentile(pixels_scaled, 0.1))\n",
    "    windowCenter = windowWidth/2\n",
    "    \n",
    "    # Generate unique UIDs\n",
    "    studyInstanceUid = generate_uid('999.')\n",
    "    seriesInstanceUid = generate_uid('9999.')\n",
    "    \n",
    "    # Create DICOM files for each slice\n",
    "    for s in range(0, slices):\n",
    "        slice_filename = \"%s_%03d.dcm\"%(patientName, s)\n",
    "        slice_full_path = outfolder/slice_filename\n",
    "        slice_pixels = pixels_scaled[s,:,:]\n",
    "        \n",
    "        # Create DICOM file metadata\n",
    "        file_meta = FileMetaDataset()\n",
    "        file_meta.MediaStorageSOPClassUID = '1.2.840.10008.5.1.4.1.1.4'\n",
    "        file_meta.MediaStorageSOPInstanceUID = generate_uid()\n",
    "        file_meta.ImplementationClassUID = generate_uid()\n",
    "        \n",
    "        # Create main dataset\n",
    "        ds = DicomDataset()\n",
    "        ds.file_meta = file_meta\n",
    "        \n",
    "        # Set basic DICOM tags\n",
    "        ds.is_little_endian = True\n",
    "        ds.is_implicit_VR = True\n",
    "        ds.SOPClassUID = '1.2.840.10008.5.1.4.1.1.4'\n",
    "        ds.SOPInstanceUID = file_meta.MediaStorageSOPInstanceUID\n",
    "        ds.StudyInstanceUID = studyInstanceUid\n",
    "        ds.SeriesInstanceUID = seriesInstanceUid\n",
    "        ds.InstanceNumber = str(s + 1)\n",
    "        ds.PatientName = patientName\n",
    "        ds.PatientID = patientName\n",
    "        \n",
    "        # Set image-specific tags\n",
    "        ds.Modality = 'MR'\n",
    "        ds.StudyDate = datetime.datetime.now().strftime('%Y%m%d')\n",
    "        ds.StudyTime = datetime.datetime.now().strftime('%H%M%S')\n",
    "        ds.SeriesDate = ds.StudyDate\n",
    "        ds.SeriesTime = ds.StudyTime\n",
    "        \n",
    "        # Image data\n",
    "        ds.SamplesPerPixel = 1\n",
    "        ds.PhotometricInterpretation = \"MONOCHROME2\"\n",
    "        ds.PixelRepresentation = 1\n",
    "        ds.HighBit = 15\n",
    "        ds.BitsStored = 16\n",
    "        ds.BitsAllocated = 16\n",
    "        ds.Columns = slice_pixels.shape[1]\n",
    "        ds.Rows = slice_pixels.shape[0]\n",
    "        ds.PixelSpacing = [pixelSizeY, pixelSizeX]\n",
    "        ds.WindowCenter = str(int(windowCenter))\n",
    "        ds.WindowWidth = str(int(windowWidth))\n",
    "        ds.PixelData = slice_pixels.tobytes()\n",
    "        \n",
    "        # Save DICOM file\n",
    "        ds.save_as(slice_full_path)\n",
    "    \n",
    "    f.close()\n",
    "    print(f\"Converted {slices} slices to DICOM format in {outfolder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ca5018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DICOM to PNG conversion function\n",
    "def dicom_to_png(dicom_path, output_path, window_center=None, window_width=None):\n",
    "    \"\"\"\n",
    "    Convert DICOM file to PNG format with proper windowing\n",
    "    \n",
    "    Args:\n",
    "        dicom_path: Path to DICOM file\n",
    "        output_path: Output path for PNG file\n",
    "        window_center: Window center value (optional)\n",
    "        window_width: Window width value (optional)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read DICOM file\n",
    "        dicom_data = pydicom.dcmread(dicom_path)\n",
    "        pixel_array = dicom_data.pixel_array\n",
    "        \n",
    "        # Apply windowing if specified\n",
    "        if window_center is None:\n",
    "            window_center = getattr(dicom_data, 'WindowCenter', None)\n",
    "        if window_width is None:\n",
    "            window_width = getattr(dicom_data, 'WindowWidth', None)\n",
    "        \n",
    "        if window_center is not None and window_width is not None:\n",
    "            if isinstance(window_center, (list, tuple)):\n",
    "                window_center = window_center[0]\n",
    "            if isinstance(window_width, (list, tuple)):\n",
    "                window_width = window_width[0]\n",
    "            \n",
    "            # Apply windowing\n",
    "            min_val = window_center - window_width // 2\n",
    "            max_val = window_center + window_width // 2\n",
    "            pixel_array = np.clip(pixel_array, min_val, max_val)\n",
    "        \n",
    "        # Normalize to 0-255 range\n",
    "        pixel_array = pixel_array.astype(np.float64)\n",
    "        pixel_array = (pixel_array - pixel_array.min()) / (pixel_array.max() - pixel_array.min())\n",
    "        pixel_array = (pixel_array * 255).astype(np.uint8)\n",
    "        \n",
    "        # Save as PNG\n",
    "        image = Image.fromarray(pixel_array)\n",
    "        image.save(output_path)\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting {dicom_path}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33834f0e",
   "metadata": {},
   "source": [
    "# ðŸ“ 3. Data Setup & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbedfa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths configuration\n",
    "# Update these paths according to your data structure\n",
    "DATA_ROOT = Path(\"/home/bictor0301/Code/JointWise\")\n",
    "FASTMRI_PATH = DATA_ROOT / \"fastmri_data\"  # Adjust to your FastMRI data location\n",
    "DICOM_OUTPUT = DATA_ROOT / \"output-folder\"\n",
    "PNG_OUTPUT = DATA_ROOT / \"png-output\"\n",
    "ANNOTATIONS_PATH = DATA_ROOT / \"annotations\"\n",
    "\n",
    "# Create output directories\n",
    "DICOM_OUTPUT.mkdir(exist_ok=True)\n",
    "PNG_OUTPUT.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"DICOM output: {DICOM_OUTPUT}\")\n",
    "print(f\"PNG output: {PNG_OUTPUT}\")\n",
    "print(f\"Annotations: {ANNOTATIONS_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf145155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process annotations\n",
    "def load_annotations():\n",
    "    \"\"\"\n",
    "    Load annotation files and create unified dataset\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to load annotation files\n",
    "        annotation_files = list(ANNOTATIONS_PATH.glob(\"*.csv\"))\n",
    "        \n",
    "        if not annotation_files:\n",
    "            print(\"âš ï¸ No annotation files found. Creating sample data for demonstration.\")\n",
    "            return create_sample_data()\n",
    "        \n",
    "        # Load annotations\n",
    "        annotations = pd.concat([pd.read_csv(f) for f in annotation_files], ignore_index=True)\n",
    "        print(f\"âœ… Loaded {len(annotations)} annotations from {len(annotation_files)} files\")\n",
    "        return annotations\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading annotations: {e}\")\n",
    "        print(\"Creating sample data for demonstration.\")\n",
    "        return create_sample_data()\n",
    "\n",
    "def create_sample_data():\n",
    "    \"\"\"\n",
    "    Create sample dataset for demonstration if real data is not available\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    # Create sample annotations\n",
    "    sample_data = {\n",
    "        'file_id': [f'sample_{i:04d}' for i in range(n_samples)],\n",
    "        'slice': np.random.randint(0, 20, n_samples),\n",
    "        'label': np.random.choice(['ACL_tear', 'Meniscus_tear'], n_samples),\n",
    "        'bbox_x': np.random.randint(50, 200, n_samples),\n",
    "        'bbox_y': np.random.randint(50, 200, n_samples),\n",
    "        'bbox_width': np.random.randint(50, 100, n_samples),\n",
    "        'bbox_height': np.random.randint(50, 100, n_samples),\n",
    "    }\n",
    "    \n",
    "    annotations = pd.DataFrame(sample_data)\n",
    "    print(f\"âœ… Created {len(annotations)} sample annotations for demonstration\")\n",
    "    return annotations\n",
    "\n",
    "# Load the annotations\n",
    "annotations = load_annotations()\n",
    "print(f\"Dataset shape: {annotations.shape}\")\n",
    "print(f\"Columns: {list(annotations.columns)}\")\n",
    "if len(annotations) > 0:\n",
    "    print(f\"\nLabel distribution:\")\n",
    "    print(annotations['label'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
