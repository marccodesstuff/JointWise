{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7299ad83",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e3a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# Essential imports for ensemble learning pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch deep learning framework\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "import timm  # For Xception and other models\n",
    "\n",
    "# Data augmentation\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Machine learning utilities\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve, roc_curve, accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Genetic algorithm for hyperparameter optimization\n",
    "import deap\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pydicom\n",
    "from pydicom.dataset import Dataset, FileMetaDataset\n",
    "from pydicom.uid import generate_uid\n",
    "import xmltodict\n",
    "\n",
    "import pydicom\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ffd1f9",
   "metadata": {},
   "source": [
    "### GPU Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb847efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup complete.\n",
      "PyTorch version: 2.8.0+cu126\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 3060\n",
      "CUDA memory: 12.0 GB\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Set deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Environment setup complete.\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99c3fb6",
   "metadata": {},
   "source": [
    "### Data Processor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad53d24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process annotations from knee.csv\n",
    "class DataProcessor:\n",
    "    def __init__(self, csv_path, png_dir):\n",
    "        self.csv_path = Path(csv_path)\n",
    "        self.png_dir = Path(png_dir)\n",
    "        self.df = None\n",
    "        self.subject_labels = {}\n",
    "        \n",
    "    def load_annotations(self):\n",
    "        \"\"\"Load and process knee annotations\"\"\"\n",
    "        self.df = pd.read_csv(self.csv_path)\n",
    "        print(f\"Loaded {len(self.df)} annotations\")\n",
    "        print(f\"Unique files: {self.df['file'].nunique()}\")\n",
    "        print(f\"Label distribution:\")\n",
    "        print(self.df['label'].value_counts())\n",
    "        return self.df\n",
    "    \n",
    "    def create_target_labels(self):\n",
    "        \"\"\"Create target labels: ACL tear, Meniscus tear, Neither - treating cases with both as separate entries\"\"\"\n",
    "        # Map detailed labels to our target classes\n",
    "        acl_keywords = ['ACL', 'Anterior Cruciate', 'Anterior Cruciate Ligament', 'ACL High Grade Sprain', 'ACL Low Grade sprain']\n",
    "        meniscus_keywords = ['Meniscus', 'Meniscus Tear']\n",
    "        \n",
    "        subject_conditions = {}\n",
    "        \n",
    "        for file_id in self.df['file'].unique():\n",
    "            file_data = self.df[self.df['file'] == file_id]\n",
    "            labels = file_data['label'].tolist()\n",
    "            \n",
    "            has_acl = any(any(keyword.lower() in label.lower() for keyword in acl_keywords) for label in labels)\n",
    "            has_meniscus = any(any(keyword.lower() in label.lower() for keyword in meniscus_keywords) for label in labels)\n",
    "            \n",
    "            # Instead of creating a \"Both\" class, we'll create separate entries\n",
    "            if has_acl and has_meniscus:\n",
    "                # Create two separate entries: one for ACL tear and one for Meniscus tear\n",
    "                subject_conditions[f\"{file_id}_ACL\"] = 'ACL_tear'\n",
    "                subject_conditions[f\"{file_id}_Meniscus\"] = 'Meniscus_tear'\n",
    "            elif has_acl:\n",
    "                subject_conditions[file_id] = 'ACL_tear'\n",
    "            elif has_meniscus:\n",
    "                subject_conditions[file_id] = 'Meniscus_tear'\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        self.subject_labels = subject_conditions\n",
    "        print(\"\nSubject-level label distribution:\")\n",
    "        label_counts = pd.Series(list(subject_conditions.values())).value_counts()\n",
    "        print(label_counts)\n",
    "        \n",
    "        return subject_conditions\n",
    "    \n",
    "    def get_bounding_boxes(self, file_id, slice_num):\n",
    "        \"\"\"Get bounding boxes for a specific file and slice\"\"\"\n",
    "        slice_data = self.df[(self.df['file'] == file_id) & (self.df['slice'] == slice_num)]\n",
    "        boxes = []\n",
    "        for _, row in slice_data.iterrows():\n",
    "            boxes.append({\n",
    "                'x': row['x'], 'y': row['y'], \n",
    "                'width': row['width'], 'height': row['height'],\n",
    "                'label': row['label']\n",
    "            })\n",
    "        return boxes\n",
    "    \n",
    "    def get_available_images(self):\n",
    "        \"\"\"Get list of available PNG images with their labels\"\"\"\n",
    "        available_images = []\n",
    "        \n",
    "        for png_file in self.png_dir.glob('*.png'):\n",
    "            # Extract file ID and slice from filename (e.g., file1000002_000.png)\n",
    "            filename = png_file.stem\n",
    "            parts = filename.split('_')\n",
    "            if len(parts) >= 2:\n",
    "                file_id = '_'.join(parts[:-1])  # Everything except last part\n",
    "                slice_num = int(parts[-1])  # Last part is slice number\n",
    "                \n",
    "                # Check for both original file_id and the special ACL/Meniscus entries\n",
    "                if file_id in self.subject_labels:\n",
    "                    available_images.append({\n",
    "                        'path': str(png_file),\n",
    "                        'file_id': file_id,\n",
    "                        'slice': slice_num,\n",
    "                        'label': self.subject_labels[file_id]\n",
    "                    })\n",
    "                \n",
    "                # Check for ACL-specific entry\n",
    "                acl_key = f\"{file_id}_ACL\"\n",
    "                if acl_key in self.subject_labels:\n",
    "                    available_images.append({\n",
    "                        'path': str(png_file),\n",
    "                        'file_id': acl_key,  # Use the modified file_id to maintain uniqueness\n",
    "                        'slice': slice_num,\n",
    "                        'label': self.subject_labels[acl_key]\n",
    "                    })\n",
    "                \n",
    "                # Check for Meniscus-specific entry\n",
    "                meniscus_key = f\"{file_id}_Meniscus\"\n",
    "                if meniscus_key in self.subject_labels:\n",
    "                    available_images.append({\n",
    "                        'path': str(png_file),\n",
    "                        'file_id': meniscus_key,  # Use the modified file_id to maintain uniqueness\n",
    "                        'slice': slice_num,\n",
    "                        'label': self.subject_labels[meniscus_key]\n",
    "                    })\n",
    "        \n",
    "        print(f\"\nFound {len(available_images)} available images\")\n",
    "        return available_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba6b9334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16167 annotations\n",
      "Unique files: 974\n",
      "Label distribution:\n",
      "label\n",
      "Meniscus Tear                                5658\n",
      "Cartilage - Partial Thickness loss/defect    2985\n",
      "Joint Effusion                               1311\n",
      "Bone-Fracture/Contusion/dislocation          1060\n",
      "Bone- Subchondral edema                       986\n",
      "Periarticular cysts                           864\n",
      "Ligament - ACL Low Grade sprain               765\n",
      "Ligament - ACL High Grade Sprain              677\n",
      "Cartilage - Full Thickness loss/defect        615\n",
      "Ligament - MCL Low-Mod Grade Sprain           285\n",
      "Displaced Meniscal Tissue                     232\n",
      "Bone - Lesion                                 183\n",
      "Ligament - PCL Low-Mod grade sprain           142\n",
      "LCL Complex - Low-Mod Grade Sprain            130\n",
      "Soft Tissue Lesion                             90\n",
      "Muscle Strain                                  65\n",
      "Joint Bodies                                   38\n",
      "Patellar Retinaculum - High grade sprain       24\n",
      "Ligament - PCL High Grade                      18\n",
      "LCL Complex- High Grade Sprain                 14\n",
      "artifact                                       13\n",
      "Ligament - MCL High Grade sprain               11\n",
      "Ligament -  High Grade Sprain                   1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Subject-level label distribution:\n",
      "Meniscus_tear    663\n",
      "ACL_tear         254\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Found 0 available images\n",
      "\n",
      "Ready to process 0 images from 917 subject entries\n",
      "\n",
      "Checking for cases with both ACL and Meniscus tears:\n",
      "Found 164 cases that have both ACL and Meniscus tears (now treated as separate entries)\n",
      "Examples: ['file1000633', 'file1001557', 'file1000120', 'file1000738', 'file1002006']\n"
     ]
    }
   ],
   "source": [
    "# Initialize data processor and test the new functionality\n",
    "data_processor = DataProcessor('/home/bictor0301/Code/JointWise/annotations/knee.csv', '/home/bictor0301/Code/JointWise/png-output')\n",
    "annotations = data_processor.load_annotations()\n",
    "subject_labels = data_processor.create_target_labels()\n",
    "available_images = data_processor.get_available_images()\n",
    "\n",
    "print(f\"\nReady to process {len(available_images)} images from {len(subject_labels)} subject entries\")\n",
    "\n",
    "# Let's also check if there are any cases that were previously \"Both\"\n",
    "print(\"\nChecking for cases with both ACL and Meniscus tears:\")\n",
    "original_files = set()\n",
    "acl_files = set()\n",
    "meniscus_files = set()\n",
    "\n",
    "for file_id, label in subject_labels.items():\n",
    "    if file_id.endswith('_ACL'):\n",
    "        acl_files.add(file_id[:-4])  # Remove _ACL suffix\n",
    "    elif file_id.endswith('_Meniscus'):\n",
    "        meniscus_files.add(file_id[:-9])  # Remove _Meniscus suffix\n",
    "    else:\n",
    "        original_files.add(file_id)\n",
    "\n",
    "both_cases = acl_files.intersection(meniscus_files)\n",
    "print(f\"Found {len(both_cases)} cases that have both ACL and Meniscus tears (now treated as separate entries)\")\n",
    "if len(both_cases) > 0:\n",
    "    print(f\"Examples: {list(both_cases)[:5]}\")  # Show first 5 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65de5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JointWise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
